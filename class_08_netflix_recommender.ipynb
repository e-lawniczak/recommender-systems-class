{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "antique-certification",
   "metadata": {},
   "source": [
    "# Netflix recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verified-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-tourist",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prepared-fraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>171</td>\n",
       "      <td>Jeffrey (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>228</td>\n",
       "      <td>Destiny Turns on the Radio (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>233</td>\n",
       "      <td>Exotica (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>267</td>\n",
       "      <td>Major Payne (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>318</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>355</td>\n",
       "      <td>Flintstones, The (1994)</td>\n",
       "      <td>Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>435</td>\n",
       "      <td>Coneheads (1993)</td>\n",
       "      <td>Comedy|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>481</td>\n",
       "      <td>Kalifornia (1993)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>780</td>\n",
       "      <td>Independence Day (a.k.a. ID4) (1996)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_id                                 title  \\\n",
       "0          1                      Toy Story (1995)   \n",
       "143      171                        Jeffrey (1995)   \n",
       "194      228     Destiny Turns on the Radio (1995)   \n",
       "199      233                        Exotica (1994)   \n",
       "230      267                    Major Payne (1995)   \n",
       "277      318      Shawshank Redemption, The (1994)   \n",
       "313      355               Flintstones, The (1994)   \n",
       "379      435                      Coneheads (1993)   \n",
       "419      481                     Kalifornia (1993)   \n",
       "615      780  Independence Day (a.k.a. ID4) (1996)   \n",
       "\n",
       "                                          genres  \n",
       "0    Adventure|Animation|Children|Comedy|Fantasy  \n",
       "143                                 Comedy|Drama  \n",
       "194                                       Comedy  \n",
       "199                                        Drama  \n",
       "230                                       Comedy  \n",
       "277                                  Crime|Drama  \n",
       "313                      Children|Comedy|Fantasy  \n",
       "379                                Comedy|Sci-Fi  \n",
       "419                               Drama|Thriller  \n",
       "615             Action|Adventure|Sci-Fi|Thriller  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions left: 2761\n"
     ]
    }
   ],
   "source": [
    "ml_ratings_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"ratings.csv\")).rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "ml_movies_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"movies.csv\")).rename(columns={'movieId': 'item_id'})\n",
    "ml_df = pd.merge(ml_ratings_df, ml_movies_df, on='item_id')\n",
    "\n",
    "# Filter the data to reduce the number of movies\n",
    "seed = 6789\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "left_ids = rng.choice(ml_movies_df['item_id'], size=90, replace=False)\n",
    "left_ids = list(set(left_ids).union(set([1, 318, 1193, 1208, 1214, 1721, 2959, 3578, 4306, 109487])))\n",
    "\n",
    "ml_ratings_df = ml_ratings_df.loc[ml_ratings_df['item_id'].isin(left_ids)]\n",
    "ml_movies_df = ml_movies_df.loc[ml_movies_df['item_id'].isin(left_ids)]\n",
    "ml_df = ml_df.loc[ml_df['item_id'].isin(left_ids)]\n",
    "\n",
    "display(ml_movies_df.head(10))\n",
    "\n",
    "print(\"Number of interactions left: {}\".format(len(ml_ratings_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-brooklyn",
   "metadata": {},
   "source": [
    "## Shift item ids and user ids so that they are consecutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valuable-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964984086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964983250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445714885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id  rating   timestamp\n",
       "0          0        0     4.0   964982703\n",
       "42         0        1     3.0   964984086\n",
       "72         0        2     4.0   964983250\n",
       "75         0        3     4.0   964981855\n",
       "97         0        4     4.0   964980985\n",
       "192        0        5     5.0   964983282\n",
       "216        0        6     4.0   964981725\n",
       "219        0        7     5.0   964980668\n",
       "232        1        8     3.0  1445714835\n",
       "235        1        7     4.0  1445714885"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactions_df = ml_ratings_df.copy()\n",
    "\n",
    "unique_item_ids = interactions_df['item_id'].unique()\n",
    "item_id_mapping = dict(zip(unique_item_ids, list(range(len(unique_item_ids)))))\n",
    "item_id_reverse_mapping = dict(zip(list(range(len(unique_item_ids))), unique_item_ids))\n",
    "unique_user_ids = interactions_df['user_id'].unique()\n",
    "user_id_mapping = dict(zip(unique_user_ids, list(range(len(unique_user_ids)))))\n",
    "user_id_reverse_mapping = dict(zip(list(range(len(unique_user_ids))), unique_user_ids))\n",
    "\n",
    "interactions_df['item_id'] = interactions_df['item_id'].map(item_id_mapping)\n",
    "interactions_df['user_id'] = interactions_df['user_id'].map(user_id_mapping)\n",
    "\n",
    "display(interactions_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-meeting",
   "metadata": {},
   "source": [
    "## Get the number of items and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "close-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_items=100\n",
      "n_users=555\n"
     ]
    }
   ],
   "source": [
    "n_items = np.max(interactions_df['item_id']) + 1\n",
    "n_users = np.max(interactions_df['user_id']) + 1\n",
    "\n",
    "print(\"n_items={}\\nn_users={}\".format(n_items, n_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-threshold",
   "metadata": {},
   "source": [
    "## Get the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extraordinary-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# mapping to int is necessary because of how iterrows works\n",
    "r = np.zeros(shape=(n_users, n_items))\n",
    "for idx, interaction in interactions_df.iterrows():\n",
    "    r[int(interaction['user_id'])][int(interaction['item_id'])] = 1\n",
    "    \n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-little",
   "metadata": {},
   "source": [
    "## Generate negative interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-crime",
   "metadata": {},
   "source": [
    "**Task 1.** Generate negative interactions, i.e. such pairs of user_id, item_id which do not appear in the original interactions (interactions_df). For every positive interaction generate n_neg_per_pos negative interactions. Store those pairs as tuples (user_id, item_id, 0) in the negative_interactions list. The last position in the tuple is an indicator if this was a positive or a negative interaction. Finally transform the negative_interactions into a DataFrame with columns 'user_id', 'item_id', 'interacted' and concatenate it to the end of the interactions_pos_neg_df DataFrame.\n",
    "\n",
    "Try to find the most efficient way to generate those negative interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "capital-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([(0, 0, 1), (0, 1, 1), (0, 2, 1), (0, 3, 1), (0, 4, 1), (0, 5, 1), (0, 6, 1), (0, 7, 1), (1, 8, 1), (1, 7, 1), (1, 9, 1), (2, 10, 1), (2, 4, 1), (2, 5, 1), (2, 11, 1), (3, 0, 1), (3, 8, 1), (4, 10, 1), (4, 12, 1), (4, 8, 1), (4, 13, 1), (4, 14, 1), (4, 1, 1), (5, 0, 1), (5, 1, 1), (5, 2, 1), (5, 7, 1), (5, 15, 1), (5, 11, 1), (6, 8, 1), (7, 5, 1), (7, 7, 1), (7, 15, 1), (7, 9, 1), (8, 8, 1), (8, 1, 1), (8, 16, 1), (9, 16, 1), (10, 16, 1), (10, 7, 1), (11, 8, 1), (12, 0, 1), (12, 8, 1), (12, 13, 1), (12, 1, 1), (12, 3, 1), (12, 5, 1), (12, 7, 1), (12, 15, 1), (12, 17, 1), (12, 9, 1), (13, 8, 1), (13, 18, 1), (13, 2, 1), (13, 3, 1), (13, 5, 1), (14, 0, 1), (14, 8, 1), (14, 1, 1), (14, 18, 1), (14, 5, 1), (15, 0, 1), (15, 8, 1), (15, 14, 1), (15, 1, 1), (15, 18, 1), (15, 2, 1), (15, 3, 1), (15, 16, 1), (15, 5, 1), (15, 7, 1), (15, 15, 1), (15, 11, 1), (15, 19, 1), (15, 9, 1), (15, 20, 1), (16, 0, 1), (16, 14, 1), (16, 18, 1), (16, 3, 1), (16, 4, 1), (16, 21, 1), (16, 22, 1), (16, 5, 1), (16, 23, 1), (16, 6, 1), (16, 7, 1), (17, 7, 1), (17, 15, 1), (17, 11, 1), (18, 0, 1), (18, 13, 1), (18, 14, 1), (18, 1, 1), (18, 3, 1), (18, 16, 1), (18, 5, 1), (18, 7, 1), (18, 15, 1), (18, 11, 1), (18, 24, 1), (18, 25, 1), (18, 9, 1), (19, 8, 1), (19, 18, 1), (19, 5, 1), (19, 7, 1), (19, 15, 1), (19, 26, 1), (19, 17, 1), (20, 18, 1), (20, 2, 1), (20, 3, 1), (20, 27, 1), (21, 8, 1), (21, 1, 1), (21, 7, 1), (21, 26, 1), (22, 7, 1), (23, 0, 1), (23, 1, 1), (23, 16, 1), (23, 6, 1), (24, 8, 1), (24, 28, 1), (24, 1, 1), (24, 2, 1), (24, 3, 1), (24, 5, 1), (24, 7, 1), (24, 17, 1), (24, 29, 1), (24, 25, 1), (24, 30, 1), (25, 8, 1), (25, 1, 1), (25, 2, 1), (25, 7, 1), (25, 17, 1), (26, 8, 1), (26, 9, 1), (27, 0, 1), (27, 1, 1), (27, 3, 1), (28, 0, 1), (28, 8, 1), (28, 1, 1), (29, 0, 1), (29, 8, 1), (29, 4, 1), (29, 16, 1), (29, 31, 1), (30, 8, 1), (30, 1, 1), (30, 16, 1), (30, 5, 1), (30, 15, 1), (31, 8, 1), (31, 4, 1), (32, 8, 1), (33, 8, 1), (33, 13, 1), (33, 14, 1), (34, 3, 1), (34, 4, 1), (35, 0, 1), (35, 32, 1), (35, 12, 1), (35, 8, 1), (35, 14, 1), (36, 2, 1), (36, 3, 1), (36, 16, 1), (36, 5, 1), (36, 7, 1), (36, 15, 1), (36, 33, 1), (37, 8, 1), (37, 1, 1), (37, 4, 1), (37, 5, 1), (37, 7, 1), (38, 0, 1), (38, 8, 1), (38, 13, 1), (38, 14, 1), (39, 0, 1), (39, 1, 1), (40, 0, 1), (40, 14, 1), (40, 1, 1), (40, 4, 1), (40, 16, 1), (40, 5, 1), (40, 7, 1), (40, 15, 1), (40, 11, 1), (41, 0, 1), (41, 8, 1), (41, 14, 1), (42, 8, 1), (42, 16, 1), (42, 5, 1), (43, 1, 1), (43, 18, 1), (44, 8, 1), (44, 3, 1), (44, 9, 1), (45, 0, 1), (45, 8, 1), (45, 2, 1), (45, 16, 1), (45, 5, 1), (45, 15, 1), (45, 11, 1), (45, 25, 1), (45, 9, 1), (46, 3, 1), (46, 4, 1), (46, 34, 1), (46, 17, 1), (47, 8, 1), (47, 5, 1), (48, 28, 1), (49, 0, 1), (49, 8, 1), (50, 8, 1), (51, 0, 1), (51, 10, 1), (51, 13, 1), (51, 1, 1), (51, 18, 1), (51, 2, 1), (51, 4, 1), (51, 16, 1), (51, 31, 1), (51, 6, 1), (51, 35, 1), (51, 7, 1), (51, 34, 1), (51, 36, 1), (52, 8, 1), (52, 14, 1), (52, 1, 1), (53, 1, 1), (53, 2, 1), (53, 6, 1), (54, 8, 1), (55, 8, 1), (55, 2, 1), (55, 3, 1), (55, 17, 1), (56, 8, 1), (56, 18, 1), (56, 16, 1), (56, 5, 1), (56, 7, 1), (56, 15, 1), (56, 11, 1), (56, 25, 1), (56, 9, 1), (57, 0, 1), (57, 8, 1), (57, 1, 1), (57, 18, 1), (57, 2, 1), (57, 3, 1), (57, 5, 1), (57, 7, 1), (57, 15, 1), (57, 33, 1), (57, 11, 1), (57, 17, 1), (57, 25, 1), (58, 0, 1), (58, 8, 1), (58, 13, 1), (58, 14, 1), (58, 1, 1), (58, 18, 1), (58, 2, 1), (58, 3, 1), (58, 5, 1), (58, 15, 1), (58, 11, 1), (58, 26, 1), (58, 37, 1), (58, 17, 1), (58, 25, 1), (59, 8, 1), (59, 5, 1), (59, 9, 1), (60, 0, 1), (60, 8, 1), (60, 28, 1), (60, 1, 1), (60, 3, 1), (60, 4, 1), (60, 5, 1), (60, 7, 1), (60, 15, 1), (60, 26, 1), (61, 8, 1), (61, 5, 1), (61, 15, 1), (61, 38, 1), (62, 0, 1), (62, 8, 1), (62, 13, 1), (62, 14, 1), (62, 1, 1), (62, 18, 1), (62, 2, 1), (62, 3, 1), (62, 4, 1), (62, 16, 1), (62, 22, 1), (62, 5, 1), (62, 7, 1), (62, 39, 1), (62, 15, 1), (62, 33, 1), (62, 11, 1), (62, 26, 1), (62, 17, 1), (62, 29, 1), (62, 40, 1), (62, 25, 1), (63, 8, 1), (63, 18, 1), (63, 16, 1), (64, 8, 1), (64, 18, 1), (64, 41, 1), (64, 15, 1), (65, 0, 1), (65, 1, 1), (66, 8, 1), (66, 1, 1), (66, 18, 1), (67, 0, 1), (67, 18, 1), (67, 15, 1), (67, 25, 1), (67, 42, 1), (67, 9, 1), (68, 18, 1), (68, 2, 1), (68, 43, 1), (69, 14, 1), (69, 3, 1), (69, 16, 1), (69, 15, 1), (70, 0, 1), (70, 8, 1), (70, 2, 1), (70, 3, 1), (70, 5, 1), (70, 25, 1), (71, 7, 1), (71, 9, 1), (72, 0, 1), (72, 8, 1), (72, 1, 1), (72, 29, 1), (73, 7, 1), (74, 8, 1), (74, 3, 1), (74, 5, 1), (74, 17, 1), (75, 8, 1), (76, 0, 1), (76, 1, 1), (76, 3, 1), (76, 16, 1), (76, 7, 1), (76, 15, 1), (76, 29, 1), (77, 8, 1), (77, 7, 1), (77, 15, 1), (77, 17, 1), (78, 8, 1), (78, 14, 1), (78, 18, 1), (78, 2, 1), (78, 3, 1), (79, 0, 1), (79, 8, 1), (79, 1, 1), (79, 16, 1), (79, 5, 1), (79, 7, 1), (79, 15, 1), (80, 8, 1), (80, 18, 1), (80, 17, 1), (81, 0, 1), (81, 15, 1), (81, 33, 1), (81, 24, 1), (81, 44, 1), (81, 45, 1), (82, 0, 1), (82, 1, 1), (83, 0, 1), (83, 8, 1), (83, 14, 1), (83, 1, 1), (83, 18, 1), (83, 2, 1), (83, 3, 1), (83, 4, 1), (83, 5, 1), (83, 7, 1), (83, 46, 1), (83, 15, 1), (83, 11, 1), (83, 26, 1), (83, 40, 1), (84, 0, 1), (84, 8, 1), (84, 16, 1), (85, 8, 1), (85, 14, 1), (86, 2, 1), (86, 3, 1), (86, 17, 1), (87, 0, 1), (87, 1, 1), (87, 3, 1), (87, 16, 1), (87, 7, 1), (88, 18, 1), (88, 7, 1), (88, 15, 1), (89, 0, 1), (89, 18, 1), (89, 3, 1), (89, 15, 1), (89, 9, 1), (90, 32, 1), (90, 8, 1), (90, 14, 1), (91, 4, 1), (92, 47, 1), (92, 5, 1), (92, 7, 1), (93, 8, 1), (94, 0, 1), (94, 8, 1), (94, 18, 1), (94, 2, 1), (94, 5, 1), (94, 41, 1), (94, 15, 1), (94, 11, 1), (94, 26, 1), (94, 25, 1), (94, 9, 1), (95, 1, 1), (95, 31, 1), (95, 15, 1), (95, 11, 1), (95, 25, 1), (96, 8, 1), (96, 18, 1), (96, 2, 1), (96, 3, 1), (96, 5, 1), (96, 43, 1), (96, 7, 1), (96, 48, 1), (96, 15, 1), (96, 33, 1), (96, 11, 1), (96, 17, 1), (96, 29, 1), (96, 25, 1), (96, 9, 1), (96, 20, 1), (96, 49, 1), (97, 8, 1), (97, 11, 1), (97, 25, 1), (98, 0, 1), (98, 8, 1), (99, 16, 1), (99, 26, 1), (100, 47, 1), (100, 8, 1), (100, 13, 1), (100, 28, 1), (100, 1, 1), (101, 18, 1), (101, 2, 1), (101, 5, 1), (102, 8, 1), (102, 16, 1), (102, 5, 1), (102, 15, 1), (102, 33, 1), (102, 11, 1), (102, 24, 1), (102, 50, 1), (102, 51, 1), (103, 0, 1), (103, 1, 1), (103, 9, 1), (104, 18, 1), (104, 16, 1), (104, 41, 1), (105, 15, 1), (105, 11, 1), (106, 1, 1), (106, 2, 1), (106, 16, 1), (106, 7, 1), (107, 1, 1), (107, 18, 1), (107, 16, 1), (107, 7, 1), (108, 8, 1), (108, 1, 1), (109, 0, 1), (109, 8, 1), (109, 7, 1), (109, 15, 1), (110, 1, 1), (111, 0, 1), (111, 8, 1), (111, 14, 1), (111, 1, 1), (112, 8, 1), (112, 1, 1), (112, 2, 1), (112, 3, 1), (112, 5, 1), (112, 43, 1), (112, 26, 1), (112, 17, 1), (112, 9, 1), (113, 8, 1), (113, 5, 1), (113, 9, 1), (114, 0, 1), (114, 8, 1), (115, 8, 1), (115, 18, 1), (115, 5, 1), (115, 17, 1), (115, 52, 1), (115, 53, 1), (115, 9, 1), (115, 54, 1), (116, 8, 1), (117, 18, 1), (117, 16, 1), (118, 1, 1), (118, 16, 1), (118, 5, 1), (118, 7, 1), (118, 15, 1), (118, 11, 1), (118, 17, 1), (118, 29, 1), (118, 25, 1), (119, 0, 1), (119, 8, 1), (120, 8, 1), (120, 18, 1), (120, 3, 1), (121, 0, 1), (121, 8, 1), (121, 13, 1), (121, 16, 1), (121, 5, 1), (121, 55, 1), (121, 15, 1), (121, 11, 1), (121, 26, 1), (122, 8, 1), (122, 1, 1), (123, 0, 1), (124, 0, 1), (124, 12, 1), (124, 8, 1), (124, 1, 1), (124, 3, 1), (124, 16, 1), (124, 5, 1), (124, 6, 1), (124, 7, 1), (124, 15, 1), (124, 11, 1), (125, 12, 1), (125, 13, 1), (125, 14, 1), (126, 0, 1), (126, 8, 1), (126, 1, 1), (126, 18, 1), (126, 2, 1), (126, 3, 1), (126, 16, 1), (126, 5, 1), (126, 35, 1), (126, 7, 1), (126, 15, 1), (127, 7, 1), (127, 15, 1), (127, 29, 1), (128, 0, 1), (128, 8, 1), (128, 1, 1), (128, 18, 1), (128, 3, 1), (128, 4, 1), (128, 16, 1), (128, 21, 1), (128, 7, 1), (128, 56, 1), (128, 15, 1), (128, 11, 1), (128, 25, 1), (129, 0, 1), (129, 8, 1), (129, 1, 1), (129, 5, 1), (129, 7, 1), (129, 15, 1), (129, 11, 1), (129, 9, 1), (130, 28, 1), (131, 16, 1), (131, 15, 1), (132, 0, 1), (132, 1, 1), (132, 18, 1), (132, 3, 1), (132, 5, 1), (132, 7, 1), (132, 15, 1), (133, 0, 1), (133, 8, 1), (134, 11, 1), (135, 1, 1), (135, 3, 1), (136, 1, 1), (137, 0, 1), (137, 1, 1), (138, 8, 1), (138, 18, 1), (138, 5, 1), (139, 0, 1), (139, 1, 1), (139, 18, 1), (139, 2, 1), (139, 16, 1), (139, 5, 1), (139, 15, 1), (139, 11, 1), (139, 9, 1), (140, 11, 1), (140, 9, 1), (141, 0, 1), (141, 5, 1), (141, 7, 1), (142, 0, 1), (142, 8, 1), (142, 18, 1), (142, 2, 1), (142, 16, 1), (142, 21, 1), (142, 43, 1), (142, 41, 1), (142, 35, 1), (142, 7, 1), (142, 26, 1), (143, 18, 1), (143, 5, 1), (144, 17, 1), (145, 0, 1), (145, 8, 1), (145, 16, 1), (145, 5, 1), (145, 15, 1), (146, 0, 1), (146, 14, 1), (146, 1, 1), (146, 57, 1), (146, 2, 1), (146, 3, 1), (146, 22, 1), (146, 5, 1), (146, 55, 1), (146, 7, 1), (146, 15, 1), (146, 29, 1), (147, 0, 1), (147, 8, 1), (148, 8, 1), (149, 16, 1), (150, 1, 1), (150, 7, 1), (151, 37, 1), (152, 0, 1), (152, 8, 1), (152, 18, 1), (152, 3, 1), (152, 4, 1), (152, 16, 1), (152, 5, 1), (152, 41, 1), (152, 7, 1), (152, 15, 1), (152, 26, 1), (152, 17, 1), (153, 0, 1), (153, 8, 1), (153, 3, 1), (153, 4, 1), (153, 15, 1), (153, 11, 1), (153, 25, 1), (154, 18, 1), (154, 2, 1), (155, 0, 1), (155, 8, 1), (155, 16, 1), (155, 15, 1), (155, 33, 1), (155, 11, 1), (155, 29, 1), (156, 8, 1), (156, 13, 1), (157, 0, 1), (157, 8, 1), (157, 1, 1), (157, 18, 1), (157, 2, 1), (157, 3, 1), (158, 7, 1), (159, 10, 1), (160, 14, 1), (160, 1, 1), (161, 58, 1), (162, 8, 1), (162, 1, 1), (163, 0, 1), (163, 8, 1), (163, 13, 1), (163, 1, 1), (163, 18, 1), (163, 3, 1), (163, 16, 1), (163, 5, 1), (163, 59, 1), (163, 15, 1), (163, 11, 1), (163, 27, 1), (163, 25, 1), (163, 52, 1), (164, 0, 1), (164, 8, 1), (164, 1, 1), (164, 18, 1), (164, 5, 1), (164, 17, 1), (165, 0, 1), (165, 8, 1), (165, 1, 1), (166, 5, 1), (167, 13, 1), (167, 14, 1), (168, 0, 1), (168, 8, 1), (168, 28, 1), (168, 1, 1), (168, 18, 1), (168, 2, 1), (168, 3, 1), (168, 4, 1), (168, 5, 1), (168, 7, 1), (168, 15, 1), (168, 11, 1), (168, 60, 1), (168, 26, 1), (168, 37, 1), (168, 29, 1), (169, 3, 1), (170, 11, 1), (170, 9, 1), (171, 0, 1), (171, 16, 1), (172, 0, 1), (172, 1, 1), (172, 18, 1), (172, 3, 1), (172, 6, 1), (172, 7, 1), (172, 15, 1), (172, 11, 1), (172, 61, 1), (173, 8, 1), (173, 1, 1), (173, 3, 1), (173, 5, 1), (173, 7, 1), (173, 37, 1), (173, 17, 1), (173, 29, 1), (173, 40, 1), (174, 8, 1), (174, 5, 1), (174, 7, 1), (175, 8, 1), (175, 18, 1), (175, 5, 1), (175, 15, 1), (175, 11, 1), (176, 0, 1), (176, 8, 1), (177, 0, 1), (177, 8, 1), (177, 18, 1), (177, 5, 1), (178, 4, 1), (179, 47, 1), (179, 8, 1), (179, 2, 1), (179, 7, 1), (179, 15, 1), (180, 3, 1), (180, 7, 1), (180, 9, 1), (181, 8, 1), (181, 18, 1), (182, 8, 1), (182, 1, 1), (182, 3, 1), (182, 5, 1), (182, 7, 1), (183, 12, 1), (183, 8, 1), (183, 1, 1), (183, 2, 1), (183, 3, 1), (183, 4, 1), (183, 16, 1), (183, 7, 1), (183, 26, 1), (184, 0, 1), (184, 8, 1), (184, 14, 1), (184, 1, 1), (184, 3, 1), (184, 4, 1), (184, 16, 1), (184, 5, 1), (184, 7, 1), (184, 15, 1), (184, 11, 1), (184, 25, 1), (184, 30, 1), (184, 42, 1), (185, 0, 1), (185, 14, 1), (185, 1, 1), (185, 16, 1), (186, 0, 1), (186, 8, 1), (186, 1, 1), (186, 2, 1), (186, 3, 1), (186, 4, 1), (186, 5, 1), (186, 6, 1), (187, 8, 1), (187, 7, 1), (187, 15, 1), (187, 11, 1), (188, 2, 1), (188, 5, 1), (188, 15, 1), (188, 62, 1), (189, 11, 1), (190, 0, 1), (190, 1, 1), (191, 8, 1), (191, 16, 1), (191, 5, 1), (191, 7, 1), (192, 14, 1), (192, 15, 1), (192, 11, 1), (193, 8, 1), (193, 5, 1), (193, 7, 1), (194, 8, 1), (194, 1, 1), (194, 5, 1), (194, 7, 1), (194, 15, 1), (194, 11, 1), (194, 9, 1), (194, 54, 1), (195, 0, 1), (195, 3, 1), (195, 16, 1), (195, 15, 1), (195, 29, 1), (196, 0, 1), (196, 1, 1), (197, 8, 1), (197, 2, 1), (197, 4, 1), (197, 5, 1), (198, 0, 1), (198, 55, 1), (198, 35, 1), (198, 7, 1), (199, 0, 1), (199, 12, 1), (199, 14, 1), (199, 1, 1), (199, 3, 1), (199, 63, 1), (199, 6, 1), (200, 0, 1), (200, 8, 1), (200, 13, 1), (200, 1, 1), (200, 4, 1), (200, 16, 1), (200, 64, 1), (200, 5, 1), (200, 7, 1), (200, 15, 1), (200, 33, 1), (200, 11, 1), (200, 29, 1), (200, 25, 1), (200, 30, 1), (201, 0, 1), (201, 8, 1), (201, 1, 1), (201, 18, 1), (201, 16, 1), (201, 5, 1), (201, 15, 1), (201, 11, 1), (201, 29, 1), (202, 8, 1), (202, 1, 1), (202, 18, 1), (202, 2, 1), (202, 3, 1), (202, 16, 1), (202, 5, 1), (202, 43, 1), (202, 35, 1), (202, 37, 1), (203, 13, 1), (203, 2, 1), (203, 16, 1), (203, 5, 1), (203, 7, 1), (203, 52, 1), (204, 0, 1), (204, 8, 1), (204, 1, 1), (204, 16, 1), (204, 15, 1), (204, 11, 1), (205, 16, 1), (206, 3, 1), (207, 0, 1), (207, 12, 1), (207, 1, 1), (207, 18, 1), (207, 16, 1), (207, 5, 1), (207, 7, 1), (207, 15, 1), (207, 11, 1), (207, 26, 1), (207, 17, 1), (207, 25, 1), (208, 8, 1), (208, 5, 1), (208, 9, 1), (209, 8, 1), (209, 3, 1), (210, 0, 1), (210, 8, 1), (210, 14, 1), (211, 8, 1), (211, 1, 1), (211, 3, 1), (211, 16, 1), (211, 5, 1), (211, 7, 1), (211, 17, 1), (211, 29, 1), (211, 25, 1), (212, 3, 1), (212, 9, 1), (213, 0, 1), (213, 8, 1), (213, 1, 1), (213, 16, 1), (213, 5, 1), (213, 7, 1), (213, 15, 1), (213, 33, 1), (213, 11, 1), (213, 29, 1), (213, 65, 1), (213, 24, 1), (213, 25, 1), (213, 42, 1), (214, 0, 1), (214, 8, 1), (214, 1, 1), (214, 18, 1), (214, 16, 1), (214, 5, 1), (214, 15, 1), (214, 37, 1), (214, 9, 1), (215, 0, 1), (215, 13, 1), (215, 3, 1), (215, 6, 1), (215, 15, 1), (216, 8, 1), (216, 13, 1), (216, 14, 1), (216, 1, 1), (217, 3, 1), (217, 22, 1), (218, 8, 1), (218, 18, 1), (219, 18, 1), (220, 0, 1), (220, 8, 1), (220, 1, 1), (220, 18, 1), (220, 2, 1), (220, 3, 1), (220, 5, 1), (220, 7, 1), (220, 15, 1), (220, 11, 1), (220, 17, 1), (220, 29, 1), (220, 25, 1), (221, 0, 1), (221, 12, 1), (221, 8, 1), (221, 13, 1), (221, 14, 1), (221, 1, 1), (222, 8, 1), (222, 18, 1), (222, 5, 1), (223, 8, 1), (224, 1, 1), (224, 7, 1), (225, 1, 1), (225, 5, 1), (225, 11, 1), (226, 0, 1), (226, 8, 1), (226, 18, 1), (226, 5, 1), (226, 7, 1), (226, 15, 1), (226, 11, 1), (226, 9, 1), (227, 15, 1), (228, 0, 1), (228, 12, 1), (228, 8, 1), (228, 1, 1), (228, 18, 1), (228, 3, 1), (228, 4, 1), (228, 16, 1), (228, 64, 1), (228, 5, 1), (228, 7, 1), (228, 15, 1), (228, 11, 1), (228, 17, 1), (228, 29, 1), (228, 9, 1), (228, 54, 1), (229, 8, 1), (230, 8, 1), (230, 2, 1), (230, 5, 1), (231, 0, 1), (232, 0, 1), (232, 8, 1), (232, 1, 1), (232, 3, 1), (232, 16, 1), (232, 5, 1), (232, 7, 1), (232, 15, 1), (232, 37, 1), (233, 12, 1), (233, 8, 1), (233, 1, 1), (233, 15, 1), (233, 17, 1), (233, 29, 1), (233, 25, 1), (233, 9, 1), (234, 4, 1), (235, 8, 1), (235, 5, 1), (236, 15, 1), (237, 4, 1), (237, 5, 1), (237, 7, 1), (237, 26, 1), (237, 17, 1), (237, 66, 1), (238, 8, 1), (239, 47, 1), (239, 8, 1), (240, 0, 1), (240, 8, 1), (240, 4, 1), (240, 16, 1), (240, 31, 1), (240, 15, 1), (240, 11, 1), (241, 0, 1), (241, 1, 1), (241, 7, 1), (241, 11, 1), (241, 25, 1), (242, 8, 1), (242, 1, 1), (242, 18, 1), (242, 3, 1), (242, 16, 1), (243, 0, 1), (243, 2, 1), (243, 4, 1), (243, 5, 1), (244, 7, 1), (245, 18, 1), (245, 2, 1), (246, 0, 1), (246, 1, 1), (247, 0, 1), (247, 1, 1), (248, 3, 1), (248, 17, 1), (249, 8, 1), (249, 16, 1), (249, 9, 1), (250, 0, 1), (250, 10, 1), (250, 14, 1), (251, 0, 1), (251, 8, 1), (251, 1, 1), (251, 18, 1), (251, 2, 1), (251, 3, 1), (251, 4, 1), (251, 16, 1), (251, 5, 1), (251, 7, 1), (251, 39, 1), (251, 15, 1), (251, 33, 1), (251, 11, 1), (251, 37, 1), (251, 17, 1), (251, 29, 1), (251, 40, 1), (251, 27, 1), (251, 24, 1), (251, 25, 1), (251, 30, 1), (251, 67, 1), (252, 0, 1), (252, 8, 1), (252, 18, 1), (252, 2, 1), (252, 4, 1), (252, 5, 1), (252, 43, 1), (252, 41, 1), (252, 7, 1), (252, 15, 1), (253, 0, 1), (253, 1, 1), (254, 0, 1), (254, 1, 1), (255, 8, 1), (256, 0, 1), (256, 8, 1), (256, 1, 1), (256, 2, 1), (256, 3, 1), (256, 5, 1), (256, 7, 1), (256, 9, 1), (257, 0, 1), (257, 16, 1), (257, 15, 1), (257, 11, 1), (257, 25, 1), (258, 0, 1), (258, 8, 1), (258, 1, 1), (258, 18, 1), (258, 2, 1), (258, 16, 1), (258, 5, 1), (258, 7, 1), (258, 15, 1), (259, 0, 1), (259, 8, 1), (259, 4, 1), (260, 12, 1), (260, 8, 1), (260, 13, 1), (260, 14, 1), (261, 18, 1), (262, 18, 1), (262, 16, 1), (262, 5, 1), (262, 7, 1), (262, 15, 1), (263, 13, 1), (263, 18, 1), (263, 2, 1), (263, 4, 1), (263, 5, 1), (263, 7, 1), (263, 15, 1), (263, 26, 1), (264, 0, 1), (264, 8, 1), (264, 13, 1), (264, 1, 1), (264, 18, 1), (264, 2, 1), (264, 3, 1), (264, 4, 1), (264, 16, 1), (264, 68, 1), (264, 69, 1), (264, 5, 1), (264, 23, 1), (264, 70, 1), (264, 35, 1), (264, 7, 1), (264, 34, 1), (264, 71, 1), (264, 15, 1), (264, 33, 1), (264, 11, 1), (264, 37, 1), (264, 40, 1), (265, 2, 1), (266, 0, 1), (266, 8, 1), (266, 18, 1), (266, 2, 1), (266, 3, 1), (266, 5, 1), (266, 43, 1), (267, 0, 1), (267, 11, 1), (268, 0, 1), (268, 8, 1), (268, 1, 1), (268, 18, 1), (268, 3, 1), (268, 16, 1), (268, 5, 1), (268, 41, 1), (268, 7, 1), (268, 15, 1), (268, 11, 1), (268, 25, 1), (269, 0, 1), (270, 12, 1), (270, 13, 1), (270, 14, 1), (270, 4, 1), (270, 23, 1), (270, 70, 1), (270, 35, 1), (270, 34, 1), (271, 8, 1), (271, 18, 1), (271, 5, 1), (272, 8, 1), (272, 5, 1), (273, 28, 1), (274, 0, 1), (274, 8, 1), (274, 1, 1), (274, 57, 1), (274, 18, 1), (274, 2, 1), (274, 3, 1), (274, 5, 1), (274, 7, 1), (274, 15, 1), (274, 33, 1), (274, 11, 1), (274, 26, 1), (274, 37, 1), (274, 29, 1), (274, 9, 1), (275, 3, 1), (275, 7, 1), (276, 8, 1), (276, 5, 1), (276, 9, 1), (277, 1, 1), (277, 18, 1), (277, 16, 1), (277, 7, 1), (277, 15, 1), (277, 11, 1), (277, 25, 1), (278, 1, 1), (279, 14, 1), (279, 3, 1), (280, 0, 1), (280, 8, 1), (280, 1, 1), (280, 3, 1), (280, 4, 1), (280, 16, 1), (281, 8, 1), (281, 1, 1), (281, 18, 1), (281, 3, 1), (281, 16, 1), (281, 5, 1), (281, 7, 1), (281, 11, 1), (281, 17, 1), (281, 29, 1), (281, 52, 1), (281, 19, 1), (281, 72, 1), (281, 9, 1), (282, 15, 1), (282, 17, 1), (282, 9, 1), (283, 0, 1), (283, 8, 1), (283, 14, 1), (283, 1, 1), (283, 18, 1), (283, 3, 1), (283, 4, 1), (283, 16, 1), (283, 73, 1), (283, 22, 1), (283, 5, 1), (283, 41, 1), (283, 7, 1), (283, 15, 1), (283, 11, 1), (283, 40, 1), (283, 74, 1), (283, 25, 1), (283, 30, 1), (284, 8, 1), (284, 13, 1), (284, 5, 1), (284, 7, 1), (284, 25, 1), (285, 8, 1), (286, 15, 1), (286, 75, 1), (287, 2, 1), (288, 1, 1), (288, 2, 1), (288, 3, 1), (289, 8, 1), (289, 1, 1), (289, 2, 1), (289, 3, 1), (289, 4, 1), (289, 68, 1), (289, 76, 1), (289, 5, 1), (289, 7, 1), (289, 61, 1), (290, 0, 1), (290, 8, 1), (290, 1, 1), (291, 8, 1), (291, 18, 1), (291, 2, 1), (291, 5, 1), (291, 7, 1), (291, 15, 1), (291, 9, 1), (292, 8, 1), (292, 1, 1), (292, 18, 1), (292, 2, 1), (292, 15, 1), (292, 11, 1), (292, 26, 1), (292, 17, 1), (292, 27, 1), (292, 25, 1), (292, 30, 1), (292, 19, 1), (292, 9, 1), (293, 8, 1), (293, 5, 1), (293, 9, 1), (294, 7, 1), (295, 13, 1), (295, 1, 1), (296, 0, 1), (296, 8, 1), (296, 1, 1), (296, 18, 1), (296, 16, 1), (296, 5, 1), (296, 7, 1), (296, 15, 1), (297, 0, 1), (297, 8, 1), (297, 9, 1), (298, 47, 1), (298, 8, 1), (298, 16, 1), (299, 8, 1), (299, 18, 1), (299, 5, 1), (299, 7, 1), (299, 9, 1), (300, 8, 1), (300, 18, 1), (301, 0, 1), (301, 8, 1), (301, 18, 1), (301, 2, 1), (301, 5, 1), (301, 15, 1), (301, 11, 1), (302, 8, 1), (302, 18, 1), (303, 0, 1), (303, 8, 1), (303, 14, 1), (303, 28, 1), (303, 1, 1), (303, 18, 1), (303, 2, 1), (303, 3, 1), (303, 4, 1), (303, 16, 1), (303, 5, 1), (303, 7, 1), (303, 15, 1), (303, 11, 1), (304, 8, 1), (304, 5, 1), (304, 7, 1), (304, 15, 1), (304, 29, 1), (305, 0, 1), (305, 8, 1), (305, 1, 1), (305, 2, 1), (305, 3, 1), (305, 5, 1), (305, 7, 1), (305, 15, 1), (306, 18, 1), (306, 77, 1), (306, 7, 1), (307, 0, 1), (307, 8, 1), (307, 3, 1), (307, 5, 1), (307, 7, 1), (307, 15, 1), (307, 11, 1), (307, 42, 1), (308, 8, 1), (308, 14, 1), (308, 1, 1), (309, 0, 1), (309, 8, 1), (309, 5, 1), (310, 0, 1), (310, 8, 1), (310, 1, 1), (311, 8, 1), (311, 5, 1), (311, 78, 1), (312, 0, 1), (312, 8, 1), (312, 18, 1), (312, 3, 1), (312, 16, 1), (312, 5, 1), (312, 7, 1), (312, 15, 1), (312, 11, 1), (312, 17, 1), (312, 25, 1), (312, 9, 1), (313, 8, 1), (313, 1, 1), (314, 0, 1), (314, 14, 1), (314, 29, 1), (314, 50, 1), (315, 5, 1), (316, 8, 1), (316, 3, 1), (316, 5, 1), (317, 8, 1), (317, 3, 1), (317, 15, 1), (318, 3, 1), (318, 59, 1), (319, 18, 1), (319, 2, 1), (319, 5, 1), (320, 0, 1), (320, 14, 1), (320, 1, 1), (321, 8, 1), (321, 2, 1), (321, 5, 1), (322, 0, 1), (323, 18, 1), (323, 16, 1), (323, 5, 1), (324, 8, 1), (324, 3, 1), (324, 16, 1), (324, 5, 1), (324, 7, 1), (324, 15, 1), (324, 17, 1), (324, 25, 1), (324, 9, 1), (325, 0, 1), (325, 12, 1), (325, 8, 1), (325, 13, 1), (325, 14, 1), (326, 8, 1), (326, 1, 1), (326, 2, 1), (326, 3, 1), (326, 16, 1), (326, 5, 1), (326, 7, 1), (326, 15, 1), (326, 29, 1), (327, 16, 1), (328, 8, 1), (328, 2, 1), (328, 4, 1), (328, 5, 1), (328, 7, 1), (328, 26, 1), (329, 0, 1), (329, 8, 1), (329, 1, 1), (329, 2, 1), (329, 4, 1), (329, 16, 1), (329, 5, 1), (329, 7, 1), (329, 15, 1), (329, 11, 1), (329, 17, 1), (330, 16, 1), (331, 0, 1), (331, 1, 1), (331, 16, 1), (331, 55, 1), (331, 15, 1), (332, 16, 1), (333, 8, 1), (333, 1, 1), (333, 3, 1), (333, 16, 1), (334, 8, 1), (334, 18, 1), (334, 2, 1), (334, 5, 1), (334, 7, 1), (334, 15, 1), (335, 8, 1), (336, 0, 1), (336, 1, 1), (337, 8, 1), (337, 7, 1), (337, 15, 1), (337, 11, 1), (337, 17, 1), (337, 25, 1), (337, 9, 1), (338, 5, 1), (338, 7, 1), (338, 29, 1), (338, 9, 1), (339, 0, 1), (339, 8, 1), (339, 35, 1), (339, 56, 1), (339, 15, 1), (339, 79, 1), (340, 28, 1), (340, 1, 1), (340, 18, 1), (340, 2, 1), (340, 3, 1), (340, 4, 1), (340, 7, 1), (340, 36, 1), (340, 46, 1), (340, 71, 1), (341, 2, 1), (341, 4, 1), (341, 16, 1), (341, 5, 1), (342, 8, 1), (342, 4, 1), (342, 16, 1), (342, 5, 1), (342, 15, 1), (343, 0, 1), (343, 8, 1), (343, 2, 1), (343, 3, 1), (344, 0, 1), (344, 8, 1), (344, 13, 1), (344, 14, 1), (345, 8, 1), (345, 1, 1), (346, 8, 1), (346, 7, 1), (347, 1, 1), (347, 3, 1), (347, 16, 1), (347, 43, 1), (347, 15, 1), (347, 11, 1), (347, 62, 1), (348, 2, 1), (348, 3, 1), (349, 0, 1), (349, 8, 1), (349, 18, 1), (349, 5, 1), (349, 9, 1), (350, 8, 1), (351, 0, 1), (351, 8, 1), (351, 13, 1), (351, 1, 1), (351, 18, 1), (351, 2, 1), (351, 3, 1), (351, 16, 1), (351, 64, 1), (351, 5, 1), (351, 7, 1), (351, 15, 1), (351, 33, 1), (351, 11, 1), (351, 17, 1), (351, 29, 1), (351, 40, 1), (351, 25, 1), (351, 42, 1), (351, 67, 1), (351, 80, 1), (352, 0, 1), (352, 8, 1), (352, 1, 1), (352, 2, 1), (352, 4, 1), (352, 16, 1), (352, 5, 1), (352, 15, 1), (352, 33, 1), (352, 11, 1), (352, 29, 1), (352, 27, 1), (352, 25, 1), (352, 42, 1), (353, 0, 1), (353, 8, 1), (353, 3, 1), (353, 16, 1), (353, 5, 1), (353, 33, 1), (353, 11, 1), (353, 25, 1), (354, 31, 1), (355, 14, 1), (355, 5, 1), (356, 0, 1), (356, 47, 1), (356, 8, 1), (356, 1, 1), (356, 2, 1), (357, 8, 1), (357, 1, 1), (358, 8, 1), (358, 28, 1), (358, 1, 1), (358, 18, 1), (358, 2, 1), (358, 3, 1), (358, 21, 1), (358, 5, 1), (358, 43, 1), (358, 35, 1), (358, 7, 1), (358, 81, 1), (358, 11, 1), (358, 26, 1), (358, 17, 1), (358, 29, 1), (358, 66, 1), (358, 40, 1), (358, 25, 1), (358, 30, 1), (359, 15, 1), (360, 0, 1), (360, 1, 1), (361, 18, 1), (361, 5, 1), (362, 0, 1), (362, 47, 1), (362, 8, 1), (362, 1, 1), (362, 18, 1), (362, 2, 1), (362, 3, 1), (362, 76, 1), (362, 5, 1), (362, 55, 1), (362, 43, 1), (362, 7, 1), (362, 15, 1), (363, 18, 1), (364, 3, 1), (364, 5, 1), (364, 7, 1), (365, 13, 1), (366, 0, 1), (366, 8, 1), (367, 0, 1), (367, 1, 1), (367, 5, 1), (367, 7, 1), (367, 15, 1), (368, 8, 1), (368, 18, 1), (368, 5, 1), (368, 7, 1), (369, 0, 1), (369, 15, 1), (370, 1, 1), (371, 8, 1), (372, 3, 1), (372, 5, 1), (373, 5, 1), (374, 8, 1), (374, 7, 1), (374, 25, 1), (374, 9, 1), (375, 8, 1), (375, 18, 1), (375, 23, 1), (375, 41, 1), (376, 8, 1), (376, 4, 1), (376, 55, 1), (376, 43, 1), (376, 41, 1), (377, 0, 1), (377, 8, 1), (377, 13, 1), (378, 0, 1), (378, 3, 1), (379, 8, 1), (379, 5, 1), (379, 33, 1), (380, 0, 1), (380, 32, 1), (380, 47, 1), (380, 12, 1), (380, 8, 1), (380, 13, 1), (380, 28, 1), (380, 1, 1), (380, 18, 1), (380, 2, 1), (380, 3, 1), (380, 4, 1), (380, 16, 1), (380, 76, 1), (380, 31, 1), (380, 22, 1), (380, 5, 1), (380, 23, 1), (380, 6, 1), (380, 35, 1), (380, 7, 1), (380, 34, 1), (380, 39, 1), (380, 15, 1), (380, 33, 1), (380, 11, 1), (380, 26, 1), (380, 37, 1), (380, 82, 1), (380, 17, 1), (380, 29, 1), (380, 66, 1), (380, 40, 1), (380, 25, 1), (380, 30, 1), (380, 52, 1), (380, 9, 1), (380, 54, 1), (381, 8, 1), (381, 18, 1), (381, 5, 1), (381, 41, 1), (381, 35, 1), (382, 8, 1), (382, 16, 1), (382, 5, 1), (382, 15, 1), (383, 8, 1), (383, 18, 1), (383, 5, 1), (383, 7, 1), (383, 15, 1), (383, 11, 1), (383, 9, 1), (384, 8, 1), (384, 16, 1), (384, 5, 1), (385, 8, 1), (385, 1, 1), (385, 2, 1), (385, 5, 1), (385, 7, 1), (385, 17, 1), (386, 0, 1), (386, 8, 1), (386, 18, 1), (386, 2, 1), (386, 16, 1), (386, 5, 1), (386, 15, 1), (386, 40, 1), (387, 8, 1), (387, 18, 1), (388, 0, 1), (388, 8, 1), (388, 1, 1), (388, 18, 1), (388, 22, 1), (388, 5, 1), (388, 41, 1), (389, 8, 1), (389, 14, 1), (390, 8, 1), (390, 18, 1), (390, 5, 1), (391, 8, 1), (391, 1, 1), (391, 3, 1), (391, 4, 1), (391, 16, 1), (391, 5, 1), (391, 7, 1), (391, 15, 1), (391, 11, 1), (391, 19, 1), (392, 8, 1), (392, 15, 1), (392, 11, 1), (393, 14, 1), (393, 2, 1), (393, 7, 1), (393, 11, 1), (394, 1, 1), (394, 2, 1), (394, 3, 1), (394, 4, 1), (394, 16, 1), (394, 5, 1), (394, 7, 1), (394, 15, 1), (394, 33, 1), (394, 11, 1), (394, 17, 1), (394, 29, 1), (395, 8, 1), (395, 15, 1), (396, 14, 1), (397, 0, 1), (397, 8, 1), (397, 1, 1), (397, 3, 1), (397, 16, 1), (397, 5, 1), (397, 7, 1), (397, 15, 1), (398, 8, 1), (398, 5, 1), (399, 0, 1), (399, 8, 1), (399, 1, 1), (399, 18, 1), (399, 2, 1), (399, 3, 1), (399, 16, 1), (399, 5, 1), (399, 7, 1), (399, 15, 1), (399, 11, 1), (399, 17, 1), (399, 25, 1), (400, 8, 1), (400, 18, 1), (400, 5, 1), (400, 7, 1), (401, 0, 1), (401, 8, 1), (401, 13, 1), (401, 14, 1), (402, 8, 1), (402, 1, 1), (402, 2, 1), (403, 0, 1), (403, 8, 1), (403, 1, 1), (403, 4, 1), (403, 16, 1), (403, 5, 1), (403, 7, 1), (403, 15, 1), (403, 33, 1), (403, 11, 1), (403, 37, 1), (403, 29, 1), (404, 8, 1), (405, 3, 1), (405, 17, 1), (406, 5, 1), (406, 15, 1), (407, 0, 1), (407, 8, 1), (407, 18, 1), (407, 5, 1), (408, 8, 1), (409, 1, 1), (409, 5, 1), (409, 11, 1), (410, 1, 1), (411, 8, 1), (412, 0, 1), (412, 13, 1), (412, 14, 1), (412, 1, 1), (412, 18, 1), (412, 2, 1), (412, 3, 1), (412, 83, 1), (412, 22, 1), (412, 5, 1), (412, 35, 1), (412, 7, 1), (412, 34, 1), (412, 75, 1), (412, 33, 1), (412, 11, 1), (412, 26, 1), (412, 37, 1), (412, 29, 1), (412, 25, 1), (412, 42, 1), (412, 19, 1), (412, 72, 1), (412, 50, 1), (412, 9, 1), (412, 84, 1), (412, 85, 1), (413, 8, 1), (413, 5, 1), (414, 18, 1), (415, 0, 1), (415, 28, 1), (415, 1, 1), (416, 1, 1), (416, 3, 1), (416, 7, 1), (416, 29, 1), (417, 0, 1), (417, 8, 1), (417, 1, 1), (417, 16, 1), (417, 5, 1), (417, 7, 1), (417, 15, 1), (418, 2, 1), (419, 8, 1), (419, 14, 1), (420, 0, 1), (420, 1, 1), (421, 5, 1), (421, 7, 1), (422, 0, 1), (422, 8, 1), (422, 5, 1), (422, 7, 1), (422, 15, 1), (422, 17, 1), (423, 8, 1), (423, 7, 1), (424, 0, 1), (424, 8, 1), (424, 2, 1), (424, 3, 1), (424, 16, 1), (424, 5, 1), (424, 23, 1), (424, 43, 1), (424, 41, 1), (424, 7, 1), (424, 86, 1), (425, 1, 1), (426, 8, 1), (426, 1, 1), (426, 5, 1), (426, 7, 1), (427, 2, 1), (427, 3, 1), (427, 21, 1), (428, 8, 1), (428, 5, 1), (428, 7, 1), (428, 15, 1), (428, 11, 1), (428, 25, 1), (428, 9, 1), (429, 1, 1), (429, 16, 1), (430, 0, 1), (430, 8, 1), (431, 0, 1), (431, 8, 1), (431, 14, 1), (431, 1, 1), (431, 18, 1), (431, 2, 1), (431, 3, 1), (431, 4, 1), (431, 35, 1), (431, 59, 1), (432, 0, 1), (432, 8, 1), (433, 0, 1), (433, 5, 1), (434, 8, 1), (434, 18, 1), (435, 8, 1), (435, 5, 1), (436, 0, 1), (436, 8, 1), (436, 1, 1), (436, 87, 1), (436, 18, 1), (436, 2, 1), (436, 3, 1), (436, 4, 1), (436, 16, 1), (436, 5, 1), (436, 23, 1), (436, 41, 1), (436, 6, 1), (436, 7, 1), (436, 88, 1), (436, 59, 1), (436, 15, 1), (436, 89, 1), (436, 33, 1), (436, 11, 1), (436, 61, 1), (436, 26, 1), (436, 37, 1), (436, 17, 1), (436, 66, 1), (436, 40, 1), (436, 27, 1), (436, 90, 1), (436, 25, 1), (436, 30, 1), (437, 7, 1), (437, 15, 1), (437, 11, 1), (437, 25, 1), (437, 9, 1), (438, 0, 1), (438, 8, 1), (439, 0, 1), (439, 8, 1), (439, 13, 1), (439, 14, 1), (439, 1, 1), (439, 18, 1), (439, 2, 1), (439, 3, 1), (439, 16, 1), (439, 76, 1), (439, 6, 1), (439, 15, 1), (439, 26, 1), (439, 17, 1), (439, 29, 1), (439, 25, 1), (440, 14, 1), (440, 33, 1), (441, 0, 1), (441, 8, 1), (441, 14, 1), (441, 28, 1), (441, 1, 1), (441, 18, 1), (441, 2, 1), (441, 3, 1), (441, 4, 1), (441, 16, 1), (441, 5, 1), (441, 7, 1), (441, 15, 1), (441, 33, 1), (441, 11, 1), (441, 26, 1), (441, 17, 1), (441, 29, 1), (441, 40, 1), (441, 25, 1), (441, 30, 1), (442, 16, 1), (443, 1, 1), (444, 0, 1), (444, 8, 1), (444, 13, 1), (444, 14, 1), (444, 1, 1), (444, 18, 1), (444, 3, 1), (444, 16, 1), (444, 5, 1), (444, 6, 1), (444, 7, 1), (444, 15, 1), (444, 11, 1), (444, 66, 1), (444, 25, 1), (444, 9, 1), (445, 0, 1), (445, 8, 1), (445, 1, 1), (445, 3, 1), (445, 16, 1), (445, 5, 1), (445, 43, 1), (445, 33, 1), (445, 37, 1), (446, 8, 1), (446, 1, 1), (447, 8, 1), (447, 5, 1), (447, 15, 1), (447, 9, 1), (448, 0, 1), (448, 8, 1), (448, 15, 1), (449, 14, 1), (449, 28, 1), (449, 1, 1), (449, 3, 1), (449, 16, 1), (449, 31, 1), (449, 5, 1), (449, 55, 1), (449, 7, 1), (449, 15, 1), (449, 11, 1), (449, 29, 1), (450, 0, 1), (450, 16, 1), (450, 5, 1), (450, 11, 1), (450, 26, 1), (451, 15, 1), (451, 11, 1), (452, 0, 1), (452, 1, 1), (453, 3, 1), (453, 16, 1), (453, 7, 1), (454, 3, 1), (454, 7, 1), (455, 8, 1), (455, 1, 1), (455, 18, 1), (455, 2, 1), (455, 16, 1), (455, 5, 1), (455, 7, 1), (455, 33, 1), (456, 15, 1), (457, 8, 1), (457, 18, 1), (457, 5, 1), (457, 9, 1), (458, 8, 1), (459, 0, 1), (459, 15, 1), (460, 1, 1), (461, 8, 1), (461, 3, 1), (462, 8, 1), (462, 28, 1), (462, 18, 1), (462, 3, 1), (462, 16, 1), (462, 5, 1), (463, 0, 1), (463, 15, 1), (463, 26, 1), (463, 91, 1), (464, 5, 1), (464, 17, 1), (465, 9, 1), (466, 0, 1), (466, 7, 1), (466, 15, 1), (466, 11, 1), (466, 42, 1), (466, 9, 1), (466, 92, 1), (467, 2, 1), (468, 8, 1), (468, 5, 1), (468, 42, 1), (468, 9, 1), (469, 8, 1), (470, 8, 1), (470, 1, 1), (470, 15, 1), (471, 0, 1), (471, 18, 1), (471, 3, 1), (471, 16, 1), (471, 69, 1), (471, 5, 1), (471, 15, 1), (471, 9, 1), (472, 8, 1), (472, 5, 1), (473, 15, 1), (474, 0, 1), (474, 8, 1), (474, 13, 1), (474, 1, 1), (474, 18, 1), (474, 16, 1), (474, 7, 1), (474, 15, 1), (474, 11, 1), (474, 25, 1), (474, 62, 1), (475, 8, 1), (476, 8, 1), (476, 3, 1), (476, 15, 1), (477, 1, 1), (478, 0, 1), (478, 8, 1), (478, 1, 1), (478, 18, 1), (478, 3, 1), (478, 4, 1), (478, 5, 1), (478, 7, 1), (479, 8, 1), (479, 16, 1), (479, 5, 1), (479, 7, 1), (480, 0, 1), (480, 8, 1), (480, 1, 1), (480, 18, 1), (480, 2, 1), (480, 3, 1), (481, 0, 1), (481, 8, 1), (481, 5, 1), (481, 7, 1), (481, 15, 1), (481, 11, 1), (481, 25, 1), (481, 58, 1), (481, 9, 1), (482, 8, 1), (482, 5, 1), (483, 1, 1), (483, 3, 1), (483, 68, 1), (483, 11, 1), (484, 0, 1), (484, 7, 1), (485, 0, 1), (485, 1, 1), (486, 8, 1), (486, 3, 1), (486, 16, 1), (486, 5, 1), (487, 0, 1), (487, 3, 1), (487, 5, 1), (487, 17, 1), (488, 0, 1), (488, 1, 1), (488, 16, 1), (488, 7, 1), (488, 15, 1), (488, 11, 1), (488, 24, 1), (488, 93, 1), (488, 50, 1), (488, 9, 1), (489, 47, 1), (490, 8, 1), (490, 16, 1), (490, 50, 1), (491, 8, 1), (491, 15, 1), (492, 5, 1), (493, 0, 1), (493, 8, 1), (494, 8, 1), (494, 16, 1), (494, 5, 1), (494, 15, 1), (494, 25, 1), (495, 12, 1), (495, 5, 1), (496, 0, 1), (496, 1, 1), (497, 7, 1), (498, 8, 1), (498, 5, 1), (499, 0, 1), (499, 8, 1), (499, 9, 1), (500, 8, 1), (500, 16, 1), (500, 5, 1), (500, 15, 1), (501, 1, 1), (501, 18, 1), (501, 2, 1), (501, 5, 1), (501, 11, 1), (502, 5, 1), (502, 37, 1), (503, 2, 1), (504, 0, 1), (504, 8, 1), (504, 14, 1), (504, 1, 1), (504, 2, 1), (504, 3, 1), (504, 4, 1), (504, 5, 1), (505, 11, 1), (505, 25, 1), (506, 8, 1), (506, 16, 1), (506, 15, 1), (506, 11, 1), (507, 16, 1), (507, 6, 1), (507, 15, 1), (508, 0, 1), (508, 8, 1), (508, 13, 1), (508, 14, 1), (508, 1, 1), (509, 0, 1), (509, 1, 1), (509, 18, 1), (509, 2, 1), (509, 3, 1), (509, 16, 1), (509, 5, 1), (509, 7, 1), (509, 15, 1), (509, 11, 1), (509, 29, 1), (509, 9, 1), (510, 0, 1), (510, 8, 1), (510, 1, 1), (510, 3, 1), (510, 16, 1), (510, 5, 1), (510, 7, 1), (510, 26, 1), (510, 17, 1), (510, 29, 1), (510, 25, 1), (510, 9, 1), (511, 0, 1), (511, 8, 1), (511, 3, 1), (511, 4, 1), (511, 5, 1), (511, 7, 1), (511, 15, 1), (511, 17, 1), (511, 94, 1), (512, 58, 1), (513, 8, 1), (513, 84, 1), (514, 8, 1), (515, 8, 1), (515, 1, 1), (516, 0, 1), (516, 81, 1), (516, 26, 1), (516, 95, 1), (516, 9, 1), (516, 20, 1), (516, 84, 1), (517, 0, 1), (517, 8, 1), (517, 1, 1), (517, 18, 1), (517, 3, 1), (517, 16, 1), (517, 5, 1), (517, 7, 1), (517, 15, 1), (518, 3, 1), (519, 0, 1), (519, 8, 1), (519, 18, 1), (519, 2, 1), (519, 3, 1), (520, 0, 1), (520, 8, 1), (520, 1, 1), (520, 18, 1), (520, 3, 1), (520, 16, 1), (520, 5, 1), (520, 6, 1), (520, 7, 1), (520, 15, 1), (520, 17, 1), (520, 9, 1), (521, 8, 1), (522, 8, 1), (522, 14, 1), (522, 1, 1), (522, 3, 1), (523, 0, 1), (523, 1, 1), (524, 0, 1), (524, 8, 1), (524, 14, 1), (524, 1, 1), (524, 18, 1), (524, 2, 1), (524, 3, 1), (524, 16, 1), (524, 5, 1), (524, 43, 1), (524, 7, 1), (524, 15, 1), (524, 37, 1), (524, 17, 1), (524, 29, 1), (524, 25, 1), (525, 8, 1), (525, 5, 1), (525, 15, 1), (525, 11, 1), (525, 9, 1), (526, 5, 1), (526, 9, 1), (527, 16, 1), (527, 15, 1), (528, 0, 1), (528, 14, 1), (529, 5, 1), (529, 37, 1), (530, 8, 1), (530, 7, 1), (530, 25, 1), (531, 0, 1), (531, 18, 1), (531, 41, 1), (532, 8, 1), (533, 8, 1), (533, 28, 1), (533, 1, 1), (534, 0, 1), (534, 8, 1), (534, 13, 1), (534, 14, 1), (534, 1, 1), (534, 18, 1), (534, 2, 1), (534, 3, 1), (534, 16, 1), (534, 5, 1), (534, 41, 1), (534, 35, 1), (534, 7, 1), (534, 15, 1), (534, 33, 1), (534, 11, 1), (534, 29, 1), (534, 25, 1), (535, 5, 1), (535, 7, 1), (536, 8, 1), (536, 13, 1), (536, 14, 1), (536, 1, 1), (537, 8, 1), (537, 1, 1), (537, 16, 1), (537, 5, 1), (537, 7, 1), (537, 15, 1), (537, 11, 1), (537, 25, 1), (538, 1, 1), (538, 2, 1), (538, 3, 1), (538, 16, 1), (538, 7, 1), (539, 1, 1), (540, 0, 1), (540, 3, 1), (540, 5, 1), (540, 7, 1), (540, 39, 1), (540, 15, 1), (540, 11, 1), (540, 17, 1), (540, 29, 1), (540, 96, 1), (540, 9, 1), (541, 0, 1), (541, 1, 1), (541, 18, 1), (541, 2, 1), (541, 3, 1), (541, 4, 1), (541, 16, 1), (541, 83, 1), (541, 31, 1), (541, 23, 1), (541, 55, 1), (542, 15, 1), (543, 0, 1), (543, 47, 1), (543, 12, 1), (543, 8, 1), (543, 13, 1), (543, 14, 1), (543, 28, 1), (543, 1, 1), (543, 2, 1), (543, 3, 1), (543, 16, 1), (543, 64, 1), (543, 76, 1), (543, 5, 1), (543, 23, 1), (543, 41, 1), (543, 6, 1), (543, 7, 1), (543, 34, 1), (543, 15, 1), (543, 75, 1), (543, 33, 1), (543, 11, 1), (543, 61, 1), (543, 26, 1), (543, 37, 1), (543, 17, 1), (543, 29, 1), (543, 40, 1), (543, 38, 1), (543, 97, 1), (543, 25, 1), (543, 30, 1), (543, 58, 1), (543, 80, 1), (543, 9, 1), (544, 0, 1), (544, 8, 1), (544, 13, 1), (544, 1, 1), (544, 3, 1), (544, 16, 1), (544, 68, 1), (544, 31, 1), (544, 22, 1), (544, 5, 1), (544, 15, 1), (544, 33, 1), (544, 11, 1), (544, 26, 1), (544, 17, 1), (544, 25, 1), (545, 0, 1), (545, 8, 1), (545, 18, 1), (545, 16, 1), (545, 5, 1), (545, 7, 1), (545, 15, 1), (545, 9, 1), (546, 10, 1), (546, 8, 1), (546, 28, 1), (546, 1, 1), (547, 0, 1), (547, 47, 1), (547, 28, 1), (547, 18, 1), (547, 2, 1), (547, 3, 1), (547, 4, 1), (547, 16, 1), (547, 31, 1), (547, 98, 1), (547, 5, 1), (547, 55, 1), (547, 63, 1), (547, 7, 1), (547, 34, 1), (548, 0, 1), (548, 47, 1), (548, 12, 1), (548, 14, 1), (549, 0, 1), (549, 1, 1), (549, 15, 1), (549, 11, 1), (549, 25, 1), (550, 0, 1), (550, 8, 1), (550, 1, 1), (550, 18, 1), (550, 2, 1), (550, 3, 1), (550, 16, 1), (550, 5, 1), (550, 55, 1), (550, 43, 1), (550, 6, 1), (550, 35, 1), (550, 7, 1), (550, 15, 1), (550, 81, 1), (550, 89, 1), (550, 33, 1), (550, 11, 1), (550, 37, 1), (550, 24, 1), (550, 25, 1), (550, 62, 1), (551, 0, 1), (551, 8, 1), (551, 1, 1), (551, 3, 1), (551, 99, 1), (552, 0, 1), (552, 8, 1), (552, 13, 1), (552, 14, 1), (552, 1, 1), (552, 18, 1), (552, 2, 1), (552, 3, 1), (552, 4, 1), (552, 16, 1), (552, 5, 1), (552, 7, 1), (552, 15, 1), (552, 33, 1), (552, 11, 1), (552, 37, 1), (552, 17, 1), (552, 29, 1), (553, 0, 1), (553, 8, 1), (554, 0, 1), (554, 8, 1), (554, 1, 1), (554, 2, 1), (554, 3, 1), (554, 16, 1), (554, 5, 1), (554, 43, 1), (554, 41, 1), (554, 7, 1), (554, 15, 1), (554, 33, 1), (554, 11, 1), (554, 26, 1), (554, 37, 1), (554, 17, 1), (554, 29, 1), (554, 40, 1), (554, 30, 1), (554, 9, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>478</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13801</th>\n",
       "      <td>33</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13802</th>\n",
       "      <td>497</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13803</th>\n",
       "      <td>137</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13804</th>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16566 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  interacted\n",
       "0            0        0           1\n",
       "42           0        1           1\n",
       "72           0        2           1\n",
       "75           0        3           1\n",
       "97           0        4           1\n",
       "...        ...      ...         ...\n",
       "13800      478       81           0\n",
       "13801       33       84           0\n",
       "13802      497       64           0\n",
       "13803      137       94           0\n",
       "13804        4       48           0\n",
       "\n",
       "[16566 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "n_neg_per_pos = 5\n",
    "interactions_pos_neg_df = interactions_df[['user_id', 'item_id']].copy()\n",
    "\n",
    "# Indicate positive interactions\n",
    "\n",
    "interactions_pos_neg_df['interacted'] = 1\n",
    "\n",
    "# Generate negative interactions\n",
    "\n",
    "negative_interactions = []\n",
    "\n",
    "########################\n",
    "# Write your code here #\n",
    "########################\n",
    "\n",
    "seed = 6789\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "interaction_dict = dict.fromkeys(interactions_pos_neg_df.to_records(index=False).tolist(), \"1\")\n",
    "print(interaction_dict.keys())\n",
    "n2 = 5 * len(interactions_pos_neg_df)\n",
    "while len(negative_interactions) < n2 :\n",
    "    t_user = rng.choice(555)\n",
    "    t_item = rng.choice(100)\n",
    "    new_interaction = (t_user, t_item, 0)\n",
    "    check_interaction = (t_user, t_item, 1)\n",
    "    if check_interaction not in interaction_dict.keys():\n",
    "        negative_interactions.append(new_interaction)\n",
    "#     cond = (interactions_pos_neg_df['user_id'] == t_user) & (interactions_pos_neg_df['item_id'] == t_item)\n",
    "#     if len(interactions_pos_neg_df.loc[cond]) == 0:\n",
    "#         negative_interactions.append(new_interaction)\n",
    "\n",
    "        \n",
    "negative_interactions = pd.DataFrame(negative_interactions, columns=['user_id', 'item_id','interacted'])\n",
    "\n",
    "interactions_pos_neg_df = pd.concat([interactions_pos_neg_df, negative_interactions], axis=0)\n",
    "display(interactions_pos_neg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-virgin",
   "metadata": {},
   "source": [
    "**Task 2.** Initialize user and item embeddings of size embedding_dim. User embeddings should be stored as a numpy array user_repr_matrix of size (n_users, embedding_dim), while item embeddings in an array item_repr_matrix of size (n_items, embedding_dim). Both matrices should initialized from the Gaussian distribution with mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "amateur-profession",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.55384326  0.28995776]\n",
      " [-0.46923701  1.80495031]\n",
      " [-0.49037341 -0.15121921]\n",
      " ...\n",
      " [-0.43528032 -0.37379991]\n",
      " [-0.00383725  3.1814677 ]\n",
      " [-0.29370816  0.21336489]]\n",
      "\n",
      "[[-0.45193749  1.33442799]\n",
      " [ 0.05942583 -0.77180582]\n",
      " [-1.57604756  1.31985401]\n",
      " [ 0.72457803  1.12398941]\n",
      " [-2.84383505  0.68639228]\n",
      " [ 0.90611796  0.24346264]\n",
      " [ 0.37150664  0.27393443]\n",
      " [ 1.1545844  -0.3169259 ]\n",
      " [ 1.70288559  0.44635168]\n",
      " [ 1.5483352   0.116946  ]\n",
      " [-0.94024256 -2.22230544]\n",
      " [ 1.94948623  0.43964253]\n",
      " [ 1.67700131  1.56280059]\n",
      " [ 1.18086166  0.34140066]\n",
      " [-0.12597979 -1.45195165]\n",
      " [-0.26048603 -0.12535205]\n",
      " [-1.25733817 -1.58234288]\n",
      " [ 0.88991681 -1.67880596]\n",
      " [-1.5415643   0.83596422]\n",
      " [-0.48575124  1.2336953 ]\n",
      " [ 0.664869    0.38821939]\n",
      " [-0.38497652 -0.02550559]\n",
      " [-0.1600649   0.19916925]\n",
      " [-0.52415476 -1.52751961]\n",
      " [-0.51168743  2.71411465]\n",
      " [ 0.53548438  0.99930379]\n",
      " [ 1.10562831 -0.61797124]\n",
      " [ 0.30645891  0.42944917]\n",
      " [-0.57810398  0.53526759]\n",
      " [-1.14830141  0.57178189]\n",
      " [-0.81171889 -0.0100384 ]\n",
      " [-0.69727237 -0.89813165]\n",
      " [-1.42638383  1.42478009]\n",
      " [ 0.61642446  0.50720273]\n",
      " [ 0.03671843  0.09443836]\n",
      " [-1.37773283  0.33947947]\n",
      " [-0.41550018  0.4401955 ]\n",
      " [ 0.86658062  0.03608035]\n",
      " [ 1.76543338 -0.7012861 ]\n",
      " [ 0.57255562  0.04477365]\n",
      " [-0.32731798  1.6109474 ]\n",
      " [ 1.17949191 -0.49685158]\n",
      " [-1.01089751  0.030981  ]\n",
      " [-0.40469104  0.46503522]\n",
      " [ 1.34857312 -0.72496106]\n",
      " [-0.1147627   0.37042929]\n",
      " [ 0.29646755  0.26814468]\n",
      " [-1.14627775  1.15375312]\n",
      " [ 1.37373468  0.9874259 ]\n",
      " [ 1.98825619 -0.62995072]\n",
      " [ 0.70245291  0.37019288]\n",
      " [-0.26969182 -0.28248515]\n",
      " [ 1.24177128 -0.62011674]\n",
      " [-0.88973724  1.23373079]\n",
      " [ 0.56907589  1.19015545]\n",
      " [ 1.2821994   0.51301139]\n",
      " [ 0.24699849 -1.54397918]\n",
      " [ 0.48484053 -0.29150438]\n",
      " [-0.00291524 -0.9294339 ]\n",
      " [ 0.96362152  0.8601508 ]\n",
      " [ 0.86296033  0.87758757]\n",
      " [-1.70585515  0.23511973]\n",
      " [-0.85845601 -0.40849014]\n",
      " [-0.04994516  1.06296969]\n",
      " [ 1.86541241 -1.22806127]\n",
      " [ 0.19641394  2.13827934]\n",
      " [-0.33116016  0.86728158]\n",
      " [ 0.29147603  0.1790278 ]\n",
      " [-1.19522148 -0.45164158]\n",
      " [ 0.52466568 -0.61213185]\n",
      " [-0.85104547 -1.75986361]\n",
      " [ 0.40110517 -0.48115342]\n",
      " [-0.84127316  0.06611333]\n",
      " [ 1.1516069  -0.28538935]\n",
      " [ 0.60459174 -0.92438849]\n",
      " [ 1.37539396  0.21597922]\n",
      " [ 0.15710749 -1.12021469]\n",
      " [-0.41998936  0.8025349 ]\n",
      " [ 0.05223929  0.3984889 ]\n",
      " [-1.57119168 -0.02164301]\n",
      " [-0.09945588  1.73423728]\n",
      " [-0.40226462 -0.0823301 ]\n",
      " [-1.36828768  0.64017233]\n",
      " [-0.63239452 -0.67211989]\n",
      " [ 0.92069476 -0.33019626]\n",
      " [-0.70415666  0.15822238]\n",
      " [ 0.61293127  0.70155157]\n",
      " [-0.30551858 -0.49359213]\n",
      " [ 0.82674184  0.26428971]\n",
      " [-0.227854    0.06421372]\n",
      " [-0.22330546  0.05281113]\n",
      " [ 0.13475549 -1.01653068]\n",
      " [-1.19576167 -0.32556412]\n",
      " [ 1.76870783  0.34901335]\n",
      " [ 1.22239538 -1.38933253]\n",
      " [-0.33450381 -0.37778079]\n",
      " [ 0.39534937  0.27107556]\n",
      " [-0.03018766 -0.75661498]\n",
      " [-1.58154878  1.88063073]\n",
      " [ 0.01094025 -0.17088841]]\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 2\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "########################\n",
    "# Write your code here #\n",
    "########################\n",
    "\n",
    "user_repr_matrix = rng.normal(0,1, size = (n_users, embedding_dim))\n",
    "item_repr_matrix = rng.normal(0,1, size = (n_items, embedding_dim))\n",
    "\n",
    "print(user_repr_matrix)\n",
    "print()\n",
    "print(item_repr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-soundtrack",
   "metadata": {},
   "source": [
    "**Task 3.** Write the perform_mf_sgd_step method which takes user representation user_repr for a single user (a 1D numpy array), item representation item_repr for a single item (a 1D numpy array), interaction value r_ui which is a binary value to be predicted (the value from the interaction matrix), learning rate lr, regularization constant reg_l, and performs a single step of the stochastic gradient descent for matrix factorization as described in the Koren, Bell, Volinksy \"Matrix Factorization Techniques for Recommender Systems\". The method should return a tuple (user_repr, item_repr, loss) of new representations and the quadratic loss which was minimized (loss before the update):\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    loss = (r_{ui} - user\\_repr * item\\_repr)^2\n",
    "$$\n",
    "</center>\n",
    "where the mutliplication sign denotes the scalar product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "collect-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.256215 -0.328377] [0.751405  0.1470054] 0.7430439999999999\n"
     ]
    }
   ],
   "source": [
    "def perform_mf_sgd_step(user_repr, item_repr, r_ui, lr, reg_l):\n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "    eui = r_ui - np.dot(user_repr , item_repr)\n",
    "    loss = np.power(eui, 2)\n",
    "    p = user_repr + (lr * ((eui * item_repr) - (reg_l * user_repr))) \n",
    "    q = item_repr + (lr * ((eui * user_repr) - (reg_l * item_repr))) \n",
    "    \n",
    "    return (p, q, loss)\n",
    "\n",
    "\n",
    "# Test\n",
    "\n",
    "user_repr = np.array([0.25, -0.33])\n",
    "item_repr = np.array([0.75, 0.15])\n",
    "r_ui = 1\n",
    "lr = 0.01\n",
    "reg_l = 0.1\n",
    "user_repr, item_repr, loss = perform_mf_sgd_step(user_repr, item_repr, r_ui, lr, reg_l)\n",
    "print(user_repr, item_repr, loss)\n",
    "assert np.abs(user_repr[0] - 0.256215) < 0.001\n",
    "assert np.abs(user_repr[1] - -0.328377) < 0.001\n",
    "assert np.abs(item_repr[0] - 0.75145857) < 0.001\n",
    "assert np.abs(item_repr[1] - 0.14701939) < 0.001\n",
    "assert np.abs(loss - 0.7430439999999999) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-sword",
   "metadata": {},
   "source": [
    "**Task 4.** Write the perform_mf_sgd_epoch method which takes interactions_df, user_repr_matrix, item_repr_matrix, learning rate lr, regularization constant reg_l as input, iterates over all rows of interactions_df, performs perform_mf_sgd_step for every row (remember that every row of interactions_df contains user_id, item_id (already consecutive hence they can be used as indices of the user representations and item representations matrices) and the interacted column which is the value to be predicted - r_ui), updates the appropriate user and item representations in the user_repr matrix, item_repr matrix matrices and increases total_loss by the loss returned by the perform_mf_sgd_step method, and finally returns a tuple (user_repr_matrix, item_repr_matrix, total_loss).\n",
    "\n",
    "To obtain consistent results and pass the assertion run the cell of task 2 again before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "saving-upset",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2734.759211576843\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_loss)\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(total_loss \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2737.6365671718963\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def perform_mf_sgd_epoch(interactions_df, user_repr_matrix, item_repr_matrix, lr, reg_l):\n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "    total_loss = 0\n",
    "    for row in interactions_df.iterrows():\n",
    "        u_i = row[1]\n",
    "        user_id = u_i['user_id']\n",
    "        item_id = u_i['item_id']\n",
    "        rui = u_i['interacted']\n",
    "        \n",
    "        p = user_repr_matrix[user_id]\n",
    "        q = item_repr_matrix[item_id]\n",
    "        \n",
    "        \n",
    "        \n",
    "        user_repr, item_repr, loss = perform_mf_sgd_step(p, q, rui, lr, reg_l)\n",
    "        \n",
    "        user_repr_matrix[user_id] = user_repr\n",
    "        item_repr_matrix[item_id] = item_repr\n",
    "        total_loss += loss\n",
    "    \n",
    "    return (user_repr_matrix, item_repr_matrix, total_loss)\n",
    "    \n",
    "\n",
    "# Test\n",
    "\n",
    "total_loss = 0\n",
    "user_repr_matrix, item_repr_matrix, total_loss \\\n",
    "    = perform_mf_sgd_epoch(interactions_pos_neg_df, user_repr_matrix, item_repr_matrix, lr, reg_l)\n",
    "\n",
    "# print(user_repr_matrix)\n",
    "print()\n",
    "# print(item_repr_matrix)\n",
    "print()\n",
    "print(total_loss)\n",
    "\n",
    "assert np.abs(total_loss - 2737.6365671718963) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-velvet",
   "metadata": {},
   "source": [
    "**Task 5.** Write the perform_mf_sgd_training method which takes interactions_df, user_repr_matrix, item_repr_matrix, n_epochs, learning rate lr, regularization constant reg_l as input, permutates the rows of interactions_df (with rng.permutation) and performs perform_mf_sgd_epoch n_epochs times, and finally returns trained user and item representations and the final loss obtained in the last epoch (user_repr_matrix, item_repr_matrix, training_last_avg_loss).\n",
    "\n",
    "To obtain consistent results and pass the assertion run the cell of tasks 2, 4 again before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "overhead-recording",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb8AAAI4CAYAAAD6TuePAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6dUlEQVR4nO3deXxc1X338e9vRvtuSSPZlmTLluRFGNuA7FAWwxMggUIgCyTQlIS0Ce2Tps3SjT7ZWppuoU3SNDSFZiMLAbK0pQkJAUJYQgAL4wXb2JaFF8mbvEi2dmnmPH/MyMjCy8ia0Z2Z+3m/XnrN3GWuf5rXtb++5557jjnnBACAnwS8LgAAgOlG+AEAfIfwAwD4DuEHAPAdwg8A4DuEHwDAdwg/AIDvEH6AR8xsh5ld6XUdgB8RfgAA3yH8gBRiZrlm9iUz2xP7+ZKZ5ca2VZrZT8ys28wOm9kzZhaIbftLM+s0s2NmtsXMrvD2NwFSW5bXBQA4wSclXShpuSQn6X8kfUrSpyX9qaQOSaHYvhdKcma2UNJHJK1wzu0xs3pJwektG0gvXPkBqeW9ku50zh1wznVJ+htJt8a2jUiaJWmuc27EOfeMiw7OG5aUK6nZzLKdczucc9s9qR5IE4QfkFpmS9o5bnlnbJ0k3SWpTdIvzKzdzO6QJOdcm6SPSfprSQfM7AEzmy0Ap0T4Aallj6S545bnxNbJOXfMOfenzrn5kq6X9Imxe3vOufudc5fEPusk/dP0lg2kF8IP8Fa2meWN/Uj6vqRPmVnIzColfUbSdyXJzK4zs0YzM0k9ijZ3RsxsoZm9OdYxZlDSgKSIN78OkB4IP8BbjygaVmM/eZJaJa2XtEHSGkmfi+3bJOlxSb2SfiPp351zTyp6v+8fJR2UtE9SlaS/mr5fAUg/xmS2AAC/4coPAOA7hB8AwHcIPwCA7xB+AADfSbnhzSorK119fb3XZQAA0sRLL7100DkXOvOer0u58Kuvr1dra6vXZQAA0oSZ7TzzXiei2RMA4DuEHwDAdwg/AIDvEH4AAN8h/AAAvkP4AQB8h/ADAPgO4QcA8B3CDwDgO4QfAMB3CD8AgO8QfgAA3yH8AAC+Q/gBAHyH8AMA+A7hBwDwHcIPAOA7hB8AwHcIPwCA7xB+AADfycjwi0Sc/mdtp8IR53UpAIAUlJHh99TWLn30gbV651ef09b9x7wuBwCQYjIy/C5fGNKXbzlPuw/369ovP6N/fXybhkcjXpcFAEgRGRl+Zqbrl83WYx9fpauXzNIXH9+qG+7+tXYc7PO6NABACsjI8BtTUZSrf7vlPN176wXa2zOg67/yrJ589YDXZQEAPJbR4TfmLefM1P9+5BLVzijQ7923Wl9+YpsidIYBAN/yRfhJUl15gX70fy/S25fX6AuPbdWHv7dGQ6Nhr8sCAHjAN+EnSfk5QX3h3cv0qWsX6+cb9+kPvvOSBkcIQADwG1+FnxTtDPPBS+frH995rp7a2qXf+9Zq9Q+Pel0WAGAa+S78xty8co7+5aZler79kN7/jRd1bHDE65IAANPEt+EnSe88v1ZfvuU8vbyrW7d/+yWNhHkWEAD8wNfhJ0nXLZ2tz9+4VL9pP6RP//crco5eoACQ6bK8LiAVvPP8WrV39ekrT7apIVSkD62a73VJAIAkIvxiPnHVArUf7NXf/2yz5lYU6C3nzPS6JABAkvi+2XNMIGD6l5uWa2lNqT76wFq9uu+o1yUBAJKE8BsnPyeo/3xfiwpzs/SxB9byEDwAZCjCb4Kqkjx9/sZz9eq+Y/rCY1u9LgcAkASE30m8eVG1blk5R/c+3a4XXzvsdTkAgAQj/E7hU9cu1pzyAn3iobU8AA8AGYbwO4XC3Cx94d3LtKd7QH/7k01elwMASCDC7zQumFuuP7ysQQ+1dug32w95XQ4AIEEIvzP4kyuaVFOWr8/9dJPCzAEIABkhrvAzs6vNbIuZtZnZHSfZvsrM1pjZqJndOGHbHDP7hZltNrNNZlafoNqnRV52UH95zSJt3HNUP3qpw+tyAAAJcMbwM7OgpLslXSOpWdItZtY8Ybddkm6TdP9JDvFtSXc55xZLWinpwFQK9sLbls7S+XPKdNcvtqh3iOmPACDdxXPlt1JSm3Ou3Tk3LOkBSTeM38E5t8M5t17SCdMixEIyyzn3WGy/Xudcf2JKnz5mpk9f16yuY0P6j19t97ocAMAUxRN+NZJ2j1vuiK2LxwJJ3Wb2YzN72czuil1Jpp3z5szQ25fP1r3PtKvjSNrlNwBgnGR3eMmSdKmkP5O0QtJ8RZtHT2Bmt5tZq5m1dnV1Jbmks/cXVy9SwKTP/3yL16UAAKYgnvDrlFQ3brk2ti4eHZLWxppMRyX9t6TzJ+7knLvXOdfinGsJhUJxHnr6zS7L1+9dPE//u36Ptnf1el0OAOAsxRN+qyU1mdk8M8uRdLOkh+M8/mpJZWY2lmhvlpTWT4z/3iXzlBMM6N6n2r0uBQBwls4YfrErto9IelTSZkkPOec2mtmdZna9JJnZCjPrkHSTpHvMbGPss2FFmzyfMLMNkkzSfybnV5kelUW5es+KOv345Q7t6xn0uhwAwFkw51Lrwe2WlhbX2trqdRmntftwvy7/51/p9y+Zp//324u9LgcAfM3MXnLOtUzmM4zwchbqygt03dJZ+t7zO9XTz6DXAJBuCL+z9IeXNahvOKzvPL/D61IAAJNE+J2lxbNKdPnCkL756x0aHGHGdwBIJ4TfFPzfyxp0qG9YP2jdfeadAQApg/CbgpXzyrWstlTfeX6nUq3jEADg1Ai/KTAz3bxyjrbu79Xa3d1elwMAiBPhN0XXLZ2l/OygHqLpEwDSBuE3RcV52bp26Sw9vHaP+pjuCADSAuGXAO9ZUae+4bB+umGv16UAAOJA+CVAy9wZmh8q1EOrafoEgHRA+CWAmendLXVq3XlEbQeY7QEAUh3hlyDvPL9GwYDxzB8ApAHCL0GqivP05kVV+tGaDo2EI16XAwA4DcIvgd7TUqeDvcN68tUDXpcCADgNwi+BLl8Y0oyCbHp9AkCKI/wSKCsY0FXN1frl5gMaGmWwawBIVYRfgl2zZJaODY3q120HvS4FAHAKhF+CXdRYoeLcLP1swz6vSwEAnALhl2C5WUFdsbhKj23eT69PAEhRhF8SXL1klrr7R/RC+2GvSwEAnAThlwSXLQgpPzuon71Cr08ASEWEXxLk5wT1fxaF9OjG/QpHmOQWAFIN4ZckVy+ZpYO9Q3pp5xGvSwEATED4JcmbF1UpJytA0ycApCDCL0mKcrO0qqlSj76yT87R9AkAqYTwS6Krl8zSnp5Bbdxz1OtSAADjEH5JtGpBpSTpqa1dHlcCABiP8EuiquI8LZ5Vome2EX4AkEoIvyRbtaBSL+08or6hUa9LAQDEEH5JtqoppJGw0/Pth7wuBQAQQ/gl2QVzZygvO6BntjHLAwCkCsIvyfKyg7pwfoWe5r4fAKQMwm8aXNoUUntXnzqO9HtdCgBAhN+0WNUUfeSBpk8ASA2E3zRorCrSrNI8HnkAgBRB+E0DM9OlTZV6dttBjTLBLQB4jvCbJpc2hXR0cFTrO3u8LgUAfI/wmyaXNFbKTHqaoc4AwHOE3zSZUZijpTWlhB8ApADCbxpd3FipdR096h9mqDMA8BLhN41WzitXOOL08q5ur0sBAF8j/KbR+XNnyExaveOw16UAgK8RftOoJC9bi2eWEH4A4DHCb5qtqJ+hl3d1a4Tn/QDAM4TfNFsxr1z9w2Ft2nPU61IAwLcIv2m2or5cEvf9AMBLhN80qy7J05zyAsIPADxE+HmgpX6GWncckXPO61IAwJcIPw+srC/Xob5htR/s87oUAPAlws8DK+bF7vu9RtMnAHiB8PPA/MpCVRTmaPWOI16XAgC+RPh5wMzUUj+DTi8A4JG4ws/MrjazLWbWZmZ3nGT7KjNbY2ajZnbjhG1hM1sb+3k4UYWnuxX15dp1uF/7jw56XQoA+M4Zw8/MgpLulnSNpGZJt5hZ84Tddkm6TdL9JznEgHNueezn+inWmzF43g8AvBPPld9KSW3OuXbn3LCkByTdMH4H59wO59x6SYzZFafm2SXKzw7S6QUAPBBP+NVI2j1uuSO2Ll55ZtZqZs+b2dtPtoOZ3R7bp7Wryx+TvWYHA1peV6aXd3d7XQoA+M50dHiZ65xrkfQ7kr5kZg0Td3DO3euca3HOtYRCoWkoKTUsrSvV5r1HNTQa9roUAPCVeMKvU1LduOXa2Lq4OOc6Y6/tkn4l6bxJ1JfRltWWaSTs9OreY16XAgC+Ek/4rZbUZGbzzCxH0s2S4uq1aWYzzCw39r5S0sWSNp1tsZlmaW2pJGl9R7e3hQCAz5wx/Jxzo5I+IulRSZslPeSc22hmd5rZ9ZJkZivMrEPSTZLuMbONsY8vltRqZuskPSnpH51zhF9MTVm+KotytHZ3j9elAICvZMWzk3PuEUmPTFj3mXHvVyvaHDrxc89JOneKNWYsM9PS2jKu/ABgmjHCi8eW1paqratXvUOjXpcCAL5B+HlsWW2ZnJNe6aTpEwCmC+HnMTq9AMD0I/w8VlGUq5qyfK2j0wsATBvCLwUsryvTOq78AGDaEH4pYGltqTqODOhQ75DXpQCALxB+KWBpbZkkaT2dXgBgWhB+KeDc2lKZSeu57wcA04LwSwFFuVlqCBXR4xMApgnhlyKW1pZqXUe3nHNelwIAGY/wSxHL68p0sHdYe3oGvS4FADIe4Zcijnd6YXJbAEg6wi9FLJ5VrKyAaQM9PgEg6Qi/FJGbFVRjVZE27z3qdSkAkPEIvxTSPKtEmwg/AEg6wi+FNM8u0f6jQ4z0AgBJRvilkMWzSiRJm/ce87gSAMhshF8KGQu/TXvp9AIAyUT4pZDywhzNKs3Tpj3c9wOAZCL8UgydXgAg+Qi/FLN4Vom2d/VpcCTsdSkAkLEIvxTTPLtE4YjTtv29XpcCABmL8EsxzXR6AYCkI/xSzJzyAhXmBOn0AgBJRPilmEDAtGhWCc/6AUASEX4paKzHZyTC3H4AkAyEXwpqnl2i3qFRdRwZ8LoUAMhIhF8KotMLACQX4ZeCFs4sVsCkTdz3A4CkIPxSUF52UPNDRfT4BIAkIfxSVPOsEia2BYAkIfxSVPPsEnV2D6i7f9jrUgAg4xB+KYq5/QAgeQi/FLVoZrEkadsBwg8AEo3wS1FVxbkqycvSln2EHwAkGuGXosxMC2cWa+t+wg8AEo3wS2ELqou1Zd8xOccwZwCQSIRfCls4s1hHB0e1/+iQ16UAQEYh/FLYgupop5ctNH0CQEIRfilsLPy2EX4AkFCEXworL8xRqDiXHp8AkGCEX4pbUF1Ej08ASDDCL8UtqC7W1v29TGwLAAlE+KW4hdXFGhgJM7EtACQQ4ZfiFsykxycAJBrhl+Kaqookift+AJBAhF+KK87LVk1ZPj0+ASCBCL80wBifAJBYhF8aaKouUntXn0bCEa9LAYCMQPilgYXVxRoOR7TzUJ/XpQBARiD80sDxMT739XpcCQBkhrjCz8yuNrMtZtZmZnecZPsqM1tjZqNmduNJtpeYWYeZfSURRftNY1WRAsbjDgCQKGcMPzMLSrpb0jWSmiXdYmbNE3bbJek2Sfef4jB/K+npsy/T3/Kyg6qvKNRWenwCQELEc+W3UlKbc67dOTcs6QFJN4zfwTm3wzm3XtIbemSY2QWSqiX9IgH1+lZ0mDPCDwASIZ7wq5G0e9xyR2zdGZlZQNK/SPqzM+x3u5m1mllrV1dXPIf2nQXVRdpxqE+DI2GvSwGAtJfsDi8flvSIc67jdDs55+51zrU451pCoVCSS0pPjdXFijjptYP0+ASAqcqKY59OSXXjlmtj6+LxW5IuNbMPSyqSlGNmvc65N3Sawek1hqLDnLUd6NXiWSUeVwMA6S2e8FstqcnM5ikaejdL+p14Du6ce+/YezO7TVILwXd25ocKFbBo+AEApuaMzZ7OuVFJH5H0qKTNkh5yzm00szvN7HpJMrMVZtYh6SZJ95jZxmQW7Ud52UHVlRcQfgCQAPFc+ck594ikRyas+8y496sVbQ493TG+Jelbk64QxzVVFRF+AJAAjPCSRhqqitR+sFejjPEJAFNC+KWRpqpijYSddh3u97oUAEhrhF8aaYxNbLuNpk8AmBLCL400hAol0eMTAKaK8EsjxXnZmlWap+2EHwBMCeGXZhqrimj2BIApIvzSTGNVkbZ39SoScV6XAgBpi/BLM41VReofDmtPz4DXpQBA2iL80kxTVXRWdzq9AMDZI/zSzNjjDoQfAJw9wi/NlBfmqKIwh/ADgCkg/NJQAz0+AWBKCL801Bgb4No5enwCwNkg/NJQU1WRegZGdLB32OtSACAtEX5p6PUxPo95XAkApCfCLw2NPe7AMGcAcHYIvzRUXZKrotwsOr0AwFki/NKQmR3v9AIAmDzCL001hKJjfAIAJo/wS1ONVUXaf3RIxwZHvC4FANIO4Zemxia23d7V53ElAJB+CL801RB73IEenwAweYRfmppTXqCsgHHfDwDOAuGXprKDAc2tKCD8AOAsEH5pLDqrO/f8AGCyCL801hAq0o6DfRoJR7wuBQDSCuGXxhpCRRqNOO063O91KQCQVgi/NEaPTwA4O4RfGpvPs34AcFYIvzRWkpet6pJcenwCwCQRfmmOMT4BYPIIvzTXEIrO7uCc87oUAEgbhF+aawgV6tjgqLp6h7wuBQDSBuGX5l7v8UmnFwCIF+GX5hrHwo/7fgAQN8Ivzc0syVNBTpDwA4BJIPzSnJkd7/QCAIgP4ZcBGkKFaudBdwCIG+GXARqritTZPaD+4VGvSwGAtED4ZYCGULTTC1d/ABAfwi8DNNDjEwAmhfDLAHMrChQwZncAgHgRfhkgNyuoOeUFzO4AAHEi/DIEA1wDQPwIvwzRUFWk9oN9CkcY4BoAzoTwyxANoUINj0bUeWTA61IAIOURfhli7HEHmj4B4MwIvwxB+AFA/Ai/DDGjMEcVhTmEHwDEgfDLIA2hIub1A4A4EH4ZpKGqkCs/AIhDXOFnZleb2RYzazOzO06yfZWZrTGzUTO7cdz6ubH1a81so5n9YSKLx4kaQkU61DesI33DXpcCACntjOFnZkFJd0u6RlKzpFvMrHnCbrsk3Sbp/gnr90r6LefccklvknSHmc2eYs04heMDXB/k6g8ATieeK7+Vktqcc+3OuWFJD0i6YfwOzrkdzrn1kiIT1g8754Zii7lx/nk4S8d7fHLfDwBOK54wqpG0e9xyR2xdXMyszszWx47xT865PSfZ53YzazWz1q6urngPjQlqZuQrJyvAfT8AOIOkX4k553Y755ZKapT0fjOrPsk+9zrnWpxzLaFQKNklZaxgwDS/kk4vAHAm8YRfp6S6ccu1sXWTErvie0XSpZP9LOIXHeCaZk8AOJ14wm+1pCYzm2dmOZJulvRwPAc3s1ozy4+9nyHpEklbzrZYnFlDqFC7DvdraDTsdSkAkLLOGH7OuVFJH5H0qKTNkh5yzm00szvN7HpJMrMVZtYh6SZJ95jZxtjHF0t6wczWSXpK0j875zYk4xdBVENVkcIRp12H+r0uBQBSVlY8OznnHpH0yIR1nxn3frWizaETP/eYpKVTrBGTMNbjs+1Ar5qqiz2uBgBSE48eZJh5lYWSGOAaAE6H8MswhblZml2aR6cXADgNwi8DNVQVceUHAKdB+GWg6OwOvXLOeV0KAKQkwi8DNYQK1Tcc1v6jQ2feGQB8iPDLQON7fAIA3ojwy0CNVbEBrrnvBwAnRfhloFBxrorzsrjyA4BTIPwykJmpsaqI8AOAUyD8MlRDqEhtNHsCwEkRfhmqsapIXceG1DMw4nUpAJBy4hrbE+mncVyPzwvmzvC4GgDTaWRkRB0dHRocHPS6lITKy8tTbW2tsrOzp3wswi9DHe/xSfgBvtPR0aHi4mLV19fLzLwuJyGcczp06JA6Ojo0b968KR+PZs8MVVdeoJysAPf9AB8aHBxURUVFxgSfFO3IV1FRkbCrWcIvQwUDpvmVhfT4BHwqk4JvTCJ/J8IvgzXwuAMAnBThl8EaQ0XafaRfgyNhr0sB4DNFRUVel3BahF8Ga6wqknNSO3P7AcAJCL8MNtbjk04vALzinNOf//mfa8mSJTr33HP14IMPSpL27t2rVatWafny5VqyZImeeeYZhcNh3Xbbbcf3/eIXv5i0unjUIYPNqyxUwJjdAfCzv/nfjdq052hCj9k8u0Sffds5ce374x//WGvXrtW6det08OBBrVixQqtWrdL999+vt771rfrkJz+pcDis/v5+rV27Vp2dnXrllVckSd3d3Qmtezyu/DJYXnZQdeUF2k74AfDIs88+q1tuuUXBYFDV1dW67LLLtHr1aq1YsULf/OY39dd//dfasGGDiouLNX/+fLW3t+uP//iP9fOf/1wlJSVJq4srvwzXGKLHJ+Bn8V6hTbdVq1bp6aef1k9/+lPddttt+sQnPqH3ve99WrdunR599FH9x3/8hx566CF94xvfSMqfz5VfhmusKtJrB/sUjjivSwHgQ5deeqkefPBBhcNhdXV16emnn9bKlSu1c+dOVVdX60Mf+pA++MEPas2aNTp48KAikYje9a536XOf+5zWrFmTtLq48stwDVVFGg5HtPtwv+orC70uB4DPvOMd79BvfvMbLVu2TGamz3/+85o5c6buu+8+3XXXXcrOzlZRUZG+/e1vq7OzUx/4wAcUiUQkSf/wD/+QtLrMudS6ImhpaXGtra1el5Ex1uw6onf++3P62vtadGVztdflAJgGmzdv1uLFi70uIylO9ruZ2UvOuZbJHIdmzwzXEOJxBwCYiPDLcKX52QoV59LpBQDGIfx8gB6fgP+k2i2tREjk70T4+UBjVZG2H+jNyL8MAN4oLy9Phw4dyqi/82Pz+eXl5SXkePT29IGm6iIdGxrV/qNDmlmamBMHQOqqra1VR0eHurq6vC4locZmck8Ews8Hxsb43Lr/GOEH+EB2dnZCZjvPZDR7+sCC6mJJ0jbu+wGAJMLPFyqLclVemKNt+495XQoApATCzyeaqoq0lfADAEmEn28sqC7Wtv30+AQAifDzjQWxHp/7jg56XQoAeI7w84nGqlinl/10egEAws8nFlS//rgDAPgd4ecTFUW5qijM4coPAET4+UpTdZG2HuDKDwAIPx9ZUF2sNnp8AgDh5ydN1cX0+AQAEX6+0nR8jE/u+wHwN8LPR46P8UmPTwA+R/j5SHlhjiqLcnjcAYDvEX4+01RVTLMnAN8j/HxmQXWR2pjVHYDPEX4+01RdrN6hUe3toccnAP8i/HymqYphzgCA8POZ13t8ct8PgH8Rfj4zozBHlUW5XPkB8LW4ws/MrjazLWbWZmZ3nGT7KjNbY2ajZnbjuPXLzew3ZrbRzNab2XsSWTzOzoLqIm09wJUfAP86Y/iZWVDS3ZKukdQs6RYza56w2y5Jt0m6f8L6fknvc86dI+lqSV8ys7Ip1owpWjizWFv3HVMkQo9PAP4Uz5XfSkltzrl259ywpAck3TB+B+fcDufcekmRCeu3Oue2xd7vkXRAUighleOsLZ5ZooGRsHYd7ve6FADwRDzhVyNp97jljti6STGzlZJyJG0/ybbbzazVzFq7urome2hM0sKZ0U4vr+7jvh8Af5qWDi9mNkvSdyR9wDkXmbjdOXevc67FOdcSCnFhmGwLqotlJr2676jXpQCAJ+IJv05JdeOWa2Pr4mJmJZJ+KumTzrnnJ1cekiE/J6h5FYV6dS9XfgD8KZ7wWy2pyczmmVmOpJslPRzPwWP7/5ekbzvnfnj2ZSLRFs4s5soPgG+dMfycc6OSPiLpUUmbJT3knNtoZnea2fWSZGYrzKxD0k2S7jGzjbGPv1vSKkm3mdna2M/yZPwimJxFM0u083C/+odHvS4FAKZdVjw7OecekfTIhHWfGfd+taLNoRM/911J351ijUiCRbOK5Vx0YtvldWVelwMA04oRXnxq8cwSSdKre2n6BOA/hJ9P1c7IV0FOkMcdAPgS4edTgYDR6QWAbxF+PrZoZole3XeMiW0B+A7h52OLZxWru39E+48OeV0KAEwrws/HFsbm9ttM0ycAnyH8fGxRrMfnFjq9APAZws/HSguyNbs0j8cdAPgO4edz0R6fXPkB8BfCz+cWzSpR24FeDY++YbINAMhYhJ/PLZpZrNGI0/auXq9LAYBpQ/j53OJZdHoB4D+En8/NqyxUTjCgzXR6AeAjhJ/PZQcDaqou0ibCD4CPEH7QktmleqWzh2HOAPgG4QctqSnRkf4R7ekZ9LoUAJgWhB/UPLtUkrSxs8fjSgBgehB+0OJZxQqY9Moe7vsB8AfCDyrIyVJDqIgrPwC+QfhBkrSkplQbufID4BOEHyRJ58wu0b6jg+o6xtx+ADIf4QdJ0jljnV720PQJIPMRfpAkNc+ODnNG0ycAPyD8IEkqzc/WnPICrvwA+ALhh+OW1JTolU6u/ABkPsIPx50zu1S7DverZ2DE61IAIKkIPxy3pCba6WUT9/0AZDjCD8edc7zTC/f9AGQ2wg/HVRblamZJHj0+AWQ8wg8niHZ64coPQGYj/HCC5tml2t7Vq4HhsNelAEDSEH44wZLZJYo4afM+mj4BZC7CDyc4tzba43P97m5vCwGAJCL8cIKZJXmqKs7Vug7u+wHIXIQfTmBmWl5XprVc+QHIYIQf3mD5nDK9drBP3f3DXpcCAElB+OENlteWSRJXfwAyFuGHNzi3tlRm0rrd3PcDkJkIP7xBcV62mqqKtHb3Ea9LAYCkIPxwUstqo51enHNelwIACUf44aSWzynTkf4R7Trc73UpAJBwhB9OanldmSQ6vQDITIQfTmphdbHysgOEH4CMRPjhpLKCAZ1bU0r4AchIhB9OaXldmTbuOarh0YjXpQBAQhF+OKXldTM0PBrRq8zwACDDEH44pWV10RkeaPoEkGkIP5xSTVm+KotytXZXt9elAEBCEX44JWZ4AJCpCD+c1nlzytTODA8AMgzhh9M6b06ZJOmlnYzzCSBzxBV+Zna1mW0xszYzu+Mk21eZ2RozGzWzGyds+7mZdZvZTxJVNKbPeXUzlB00vbjjsNelAEDCnDH8zCwo6W5J10hqlnSLmTVP2G2XpNsk3X+SQ9wl6daplQmv5OcEtaSmVKtfI/wAZI54rvxWSmpzzrU754YlPSDphvE7OOd2OOfWS3rD09DOuSckHUtEsfDGyvpybejs0eBI2OtSACAh4gm/Gkm7xy13xNbBJ1bUl2sk7PQyjzwAyBAp0eHFzG43s1Yza+3q6vK6HEzQUj9DkrSa+34AMkQ84dcpqW7ccm1sXcI45+51zrU451pCoVAiD40EKCvI0cLqYsIPQMaIJ/xWS2oys3lmliPpZkkPJ7cspJoV82Zozc4jGg0zyDWA9HfG8HPOjUr6iKRHJW2W9JBzbqOZ3Wlm10uSma0wsw5JN0m6x8w2jn3ezJ6R9ANJV5hZh5m9NRm/CJJrRX25+obD2rSXQa4BpL+seHZyzj0i6ZEJ6z4z7v1qRZtDT/bZS6dSIFLDynnlkqQXXzuspbVl3hYDAFOUEh1ekPpmleardkY+9/0AZATCD3FbWV+u1h1H5JzzuhQAmBLCD3FbMa9ch/qGtb2rz+tSAGBKCD/EbUV99L4fTZ8A0h3hh7g1hApVUZjDOJ8A0h7hh7iZmVbUl+uF1w5z3w9AWiP8MCkXNVaos3tAuw73e10KAJw1wg+TcnFjpSTpmW0HPa4EAM4e4YdJmV9ZqNmlefp1G+EHIH0RfpgUM9PFjZV6bvshhSPc9wOQngg/TNolTZXqGRjRK509XpcCAGeF8MOkjd33e5amTwBpivDDpFUW5WrxrBI9S6cXAGmK8MNZuaSxQi/tPKKB4bDXpQDApBF+OCuXNIU0HI7oRYY6A5CGCD+clZX15coJBnjkAUBaIvxwVvJzgrpg7gwedgeQlgg/nLVLmiq1ee9RHewd8roUAJgUwg9n7ZLYIw80fQJIN4QfztqSmlKV5mfT9Akg7RB+OGvBgOmyBSH9assBRRjqDEAaIfwwJVcsrtLB3mGt7ej2uhQAiBvhhym5fEGVggHT45v2e10KAMSN8MOUlBZka2V9uZ7YfMDrUgAgboQfpuyKxVXasv+YdjO7O4A0Qfhhyq5qrpYkPb6Zpk8A6YHww5TNrShUY1URTZ8A0gbhh4S4YnGVXnjtkI4OjnhdCgCcEeGHhLhqcbVGwk5Pb+3yuhQAOCPCDwlx3pwZKi/MoekTQFog/JAQwYDp8oUhPbnlgEbDEa/LAYDTIvyQMFctrlZ3/4he2nnE61IA4LQIPyTMpQtCys0K6Gev7PO6FAA4LcIPCVOUm6X/s7BKP92wV2EGugaQwgg/JNTbls1W17EhvfDaIa9LAYBTIvyQUG9eVKWCnKB+sn6v16UAwCkRfkio/JygrlxcrZ9t2KsRen0CSFGEHxLubctm60j/iH7dxgzvAFIT4YeEW7WgUsV5WfrfdTR9AkhNhB8SLjcrqKvPmalfbNynwZGw1+UAwBsQfkiK65bN1rGhUcb6BJCSCD8kxUUNFSovzNH/0usTQAoi/JAU2cGArlkyU49v2q/+4VGvywGAExB+SJobltdoYCSsn21guDMAqYXwQ9KsqJ+heZWFenD1bq9LAYATEH5IGjPTu1vq9OKOw9re1et1OQBwHOGHpHrXBTUKBkwPcfUHIIUQfkiqquI8XbGoSj9a08FwZwBSBuGHpHvPijod7B3WE5sPeF0KAEgi/DANLlsQUnVJrh5cvcvrUgBAEuGHaZAVDOimC+r01NYu7e0Z8LocACD8MD3e3VKniJN+2NrhdSkAEF/4mdnVZrbFzNrM7I6TbF9lZmvMbNTMbpyw7f1mti328/5EFY70MqeiQBc1VOiB1bsVjjivywHgc2cMPzMLSrpb0jWSmiXdYmbNE3bbJek2SfdP+Gy5pM9KepOklZI+a2Yzpl420tGtF85VZ/eAHtu03+tSAPhcPFd+KyW1OefanXPDkh6QdMP4HZxzO5xz6yVN7Mv+VkmPOecOO+eOSHpM0tUJqBtp6C3nzFTtjHx9/dl2r0sB4HPxhF+NpPFPKHfE1sUjrs+a2e1m1mpmrV1dTIGTqYIB0wcunqfVO45o3e5ur8sB4GMp0eHFOXevc67FOdcSCoW8LgdJ9O6WWhXlZunrz77mdSkAfCye8OuUVDduuTa2Lh5T+SwyUHFetm5eUadHNuzVnm4eewDgjXjCb7WkJjObZ2Y5km6W9HCcx39U0lvMbEaso8tbYuvgY++/qF4R53Tfb3Z4XQoAnzpj+DnnRiV9RNHQ2izpIefcRjO708yulyQzW2FmHZJuknSPmW2MffawpL9VNEBXS7oztg4+VldeoGuWzNL3X9ilviEmugUw/cy51HrmqqWlxbW2tnpdBpLspZ1H9K6vPqe/uf4cvf+ieq/LAZDGzOwl51zLZD6TEh1e4D8XzJ2h8+eU6d6n2zU8ymwPAKYX4QfP/MkVTersHtAPXmKuPwDTi/CDZy5bENJ5c8p09y/bNDQa9rocAD5C+MEzZqaPX7lAe3oG9RADXgOYRoQfPHVpU6UumDtD//4kV38Apg/hB0+ZmT5x1QLt7RnUg6u59wdgehB+8NxFDRVaWV+uu59s0+AIV38Ako/wg+fMTB+7qkn7jw7pu8/v9LocAD5A+CElXNRQqUubKvXlJ7bpcN+w1+UAyHCEH1LGZ65rVt9wWF94bIvXpQDIcIQfUkZTdbF+901zdP8Lu/TqvqNelwMggxF+SCkfu3KBivOy9bc/2aRUG3cWQOYg/JBSZhTm6GNXNunXbYf02Kb9XpcDIEMRfkg5v3vhXDVWFenvHtnMg+8AkoLwQ8rJDgb06euatfNQv/79ye1elwMgAxF+SEmXLQjphuWzdfeTbXR+AZBwhB9S1mffdo5K87P1Fz9cr9Ewc/4BSBzCDymrvDBHf339OVrf0aOvP/ua1+UAyCCEH1LadUtn6S3N1frCY1vV3tXrdTkAMgThh5RmZvrc25coNyugv/zReoUjPPsHYOoIP6S8qpI8ffZt52j1jiO6+8k2r8sBkAEIP6SFd55fo7cvn60vPb5Vz7cf8rocAGmO8ENaMDN97h3nam5FoT76wMs61DvkdUkA0hjhh7RRlJulr/zOeTrSP6I//cE6Rbj/B+AsEX5IK+fMLtWnrl2sX23p0r3PtHtdDoA0Rfgh7dx64Vz99rkz9fmfv6ontxzwuhwAaYjwQ9oxM9114zItmlmiP77/ZW3Zd8zrkgCkGcIPaakwN0tfv61F+TlB/f59q3WQDjAAJoHwQ9qaVZqvr72vRV3HhvSH33mJ6Y8AxI3wQ1pbVlemf3n3MrXuPKJPPLSOEWAAxCXL6wKAqbpu6Wzt6R7Q3z/yqgpzgvrHdy5VIGBelwUghRF+yAi3r2pQ7+CovvzLNhXkZOmzb2uWGQEI4OQIP2SMj1+1QL1DYX3j16+pMDeoP3/rIq9LApCiCD9kDDPTp69brP7hUd395HZJ0p+9ZSFXgADegPBDRjEz/d07zpUk3f3kdh0dGNXfXH8O9wABnIDwQ8YJBkz/8M5zVZqfrXuebtfRwRH9803LlB2kczOAKMIPGcnM9Fe/vVilBdn6/M+36NjgqP7tlvNUmMspD4Dn/JDhPnx5o/7uHUv0qy0H9K6vPqeOI/1elwQgBRB+yHjvfdNcffMDK9XZPaAbvvJrte447HVJADxG+MEXLlsQ0n99+GIV52Xplv98Xg+8uEvOMRoM4FeEH3yjsapI//1HF+tN8yp0x4836BMPrVPv0KjXZQHwAOEHXykryNF9v7dSH79ygf5nbafe9m/P6pXOHq/LAjDNCD/4TjBg+uiVTbr/QxdqYDisd/77c/rPp9sZFBvwEcIPvnXh/Ao98tFLddnCkP7ukc1611ef07b9TIwL+AHhB18rL8zRvbdeoH+9ebl2HurTtV9+Vnc/2aaRcMTr0gAkEeEH3zMz3bC8Rr/4+GW6qrladz26Rdf86zN6ZluX16UBSBLCD4gJFefq7veer6+9r0XDoxHd+vUX9QffadXuwzwYD2QaxnoCJriyuVqXNFXq68++pq/8sk1XbHlKt144Vx++vEEVRblelwcgASzVHvRtaWlxra2tXpcBSJL29gzoC7/Yqh+t6VB+dlC/f8k8fXDVfJXkZXtdGoAYM3vJOdcyqc8QfsCZtR3o1Rce26JHNuxTSV6W3n9RvW67qJ4rQSAFEH5Akm3o6NFXntymRzfuV152QDevmKPfv2Se6soLvC4N8K2zCb+4OryY2dVmtsXM2szsjpNszzWzB2PbXzCz+tj6HDP7ppltMLN1Znb5ZIoDUs25taW659YWPf6JVbr23Nn67vM7ddldT+pD327Vs9sOMl4okCbOeOVnZkFJWyVdJalD0mpJtzjnNo3b58OSljrn/tDMbpb0Dufce8zsjyS1OOc+YGZVkn4maYVz7pQPUXHlh3Syp3tA33thp77/4m4d7htWY1WRbl5Rp3ecV0OTKDBNknXlt1JSm3Ou3Tk3LOkBSTdM2OcGSffF3v9Q0hVmZpKaJf1SkpxzByR1S5pUgUAqm12Wrz9/6yI9d8eb9S83LVNhbpY+99PNetPfP6E/+E6rHt+0X8OjPDAPpJp4HnWokbR73HKHpDedah/n3KiZ9UiqkLRO0vVm9n1JdZIuiL2+OP7DZna7pNslac6cOZP/LQCP5WUH9a4LavWuC2q1df8x/aB1t368plOPbtyvsoJsXbNkpt62dLbeNL9CwYB5XS7ge8l+zu8bkhZLapW0U9JzksITd3LO3SvpXina7JnkmoCkWlBdrE9e26y/uHqRntrSpZ+s36P/WbtH339xtyqLcnTl4mq95ZxqXdRQqbzsoNflAr4UT/h1Knq1NqY2tu5k+3SYWZakUkmHXPSG4sfHdjKz5xS9fwhkvOxgQFc2V+vK5moNDIf1y1cP6Gev7NVP1u/VA6t3qyAnqEubKnXZgipdtjCkmrJ8r0sGfCOe8FstqcnM5ikacjdL+p0J+zws6f2SfiPpRkm/dM45MytQtFNNn5ldJWl0fEcZwC/yc4K6duksXbt0loZGw3q+/bB+sXGfnnz1gB7duF9SdLLdSxor9VsNFbpwXoVKC3iQHkiWM4Zf7B7eRyQ9Kiko6RvOuY1mdqekVufcw5K+Luk7ZtYm6bCiASlJVZIeNbOIosF5azJ+CSCd5GYFddmCkC5bEJJzTtu7evWrLV16amuXHli9S996bofMpOZZJVpRX66W+hlqmVuumaV5XpcOZAwecgdSyNBoWOt29+g32w/p+fZDWru7WwMj0dvkNWX5Wj6nTMtry7SsrkxLakpUkMPwvAAjvAAZZiQc0aY9R9W684jW7Dyitbu71dk9IEkyk+ZXFmpJTanOmV2ixbNKtHBmsUJFuYo+aQT4A+EH+EDXsSGt292tDZ092rjnqDbt6dGensHj28sLc7SwulhN1UVqrCpSYyj6GiomFJGZzib8aDMB0kyoOPd4L9Ixh/uG9eq+o9qy75i27DumV/cd03+t6dSxodHj+xTmBDUvVKj6ikLNqyzUnPICzSkv0NyKQlUV5yrA84fwEcIPyADlhTm6qKFSFzVUHl/nnNP+o0NqO9Cr7V29eu1gn1472Kf1HT16ZMNeRcY1+uQEA6qZka+asnzVzsjX7LJ8zSrNO/46szSP+4vIKJzNQIYyM82MBdclTZUnbBsJR9R5ZEC7Dvdr5+F+dRzpV8eRAXUeGdDjmw/oYO/QG45XnJelmSV5qi7JU1VxrkLjfiqLxn5yVFaQwyg2SHmEH+BD2cGA6isLVV9ZeNLtQ6Nh7esZ1J7uQe3tGdC+o4Pa3zMYfT06pNcO9qnr2JCGw28ctzRgUllBjsoLYz8FOZpRmB1dV5Cj0oJsleZnqyw/+/j70vxs5WcHuSeJaUP4AXiD3Kyg5lYUam7FycNRijar9gyM6GDvkLqODetg75AO9g7pcN+wDvUN63DvsA73DWt7V6+O7BxRd/+wRiOn7mCXHTQV52WrOC8r+pMbfV+Ul6WSvGwV5WapMDdLRblBFeVlqTAnulyQEzz+WpATfc3NChCkOC3CD8BZMTOVFUSbORurzry/c07HhkbV0z+inoERdcdejw5GX3sGRnRscERHB0ajr4Oj2nW4X8cGR9U7FF13muw8QcCk/Oyg8nOiPwXZWcrLCSo/O6C87KDysqLr87IDys0KKi87Gphjr7mx9blZAeVmBZSTFV3OGbecE4y9ZgWUHYyuzw4GaPJNE4QfgGlhZirJy1ZJXvYJgwXHyzmnwZGIeoeiYdg3NKr+4bD6hl9/3z80qv6RsPqHwhoYCat/OKzBkbD6h0c1OBLRwEhYh/uGNTAc1uBoWIMjEQ2OhDU0GknY1FMBizYr5wQDygqasoOB2E/0fdb49wFTVtCUFYiuywoEFAyasgOmYGxdMGDKii1nnbAcfQ2M2x40KRgMKGimYEAKWHS/YMCOv3993bjtZrJx682i6wJmCsT2C9jr26LL0fVmr28P2Nj219dZ7POm1/cf/xmv/rNA+AFIC2Z2/EouVJz4iYIjEafh8OthODQS0dBo7P1o9P1w7P1IOBqWw2Pvw+748mgkouFwRCOjTsPhsEbDTiNhp5FwJPbjNBqJxNZHNDgS0Wh4VCNhp3DEaSQSUTjiNBrbLxxxGo0thyMuthyJ+yo4lV3cWKHvffBCT/5swg8AJAUCprxAMG2mmYpEnMLu9UAMO6dweMK642Hp5Nzr2yIRvf5+3OvY+oiL7R+RwhEnKfo+cnybjv+ZctH1TtF1Top91iniou+dG/us5BRdds6pZoZ3M5kQfgCQhgIBU0CmNMnqlBPwugAAAKYb4QcA8B3CDwDgO4QfAMB3CD8AgO8QfgAA3yH8AAC+Q/gBAHyH8AMA+A7hBwDwHcIPAOA7hB8AwHcIPwCA7xB+AADfIfwAAL5D+AEAfIfwAwD4DuEHAPAdwg8A4DuEHwDAdwg/AIDvmHPO6xpOYGZdknYm6HCVkg4m6FiZju8qfnxX8eO7mhy+r/iN/67mOudCk/lwyoVfIplZq3Ouxes60gHfVfz4ruLHdzU5fF/xm+p3RbMnAMB3CD8AgO9kevjd63UBaYTvKn58V/Hju5ocvq/4Tem7yuh7fgAAnEymX/kBAPAGhB8AwHcyMvzM7Goz22JmbWZ2h9f1pBIzqzOzJ81sk5ltNLOPxtaXm9ljZrYt9jrD61pThZkFzexlM/tJbHmemb0QO78eNLMcr2tMFWZWZmY/NLNXzWyzmf0W59bJmdnHY38HXzGz75tZHufW68zsG2Z2wMxeGbfupOeSRX059r2tN7Pzz3T8jAs/MwtKulvSNZKaJd1iZs3eVpVSRiX9qXOuWdKFkv4o9v3cIekJ51yTpCdiy4j6qKTN45b/SdIXnXONko5I+n1PqkpN/yrp5865RZKWKfq9cW5NYGY1kv5EUotzbomkoKSbxbk13rckXT1h3anOpWskNcV+bpf01TMdPOPCT9JKSW3OuXbn3LCkByTd4HFNKcM5t9c5tyb2/pii/zjVKPod3Rfb7T5Jb/ekwBRjZrWSrpX0tdiySXqzpB/GduG7ijGzUkmrJH1dkpxzw865bnFunUqWpHwzy5JUIGmvOLeOc849LenwhNWnOpdukPRtF/W8pDIzm3W642di+NVI2j1uuSO2DhOYWb2k8yS9IKnaObc3tmmfpGqv6koxX5L0F5IiseUKSd3OudHYMufX6+ZJ6pL0zVgz8dfMrFCcW2/gnOuU9M+Sdikaej2SXhLn1pmc6lya9L/7mRh+iIOZFUn6kaSPOeeOjt/mos+/+P4ZGDO7TtIB59xLXteSJrIknS/pq8658yT1aUITJ+dWVOxe1Q2K/odhtqRCvbGJD6cx1XMpE8OvU1LduOXa2DrEmFm2osH3Pefcj2Or9481E8ReD3hVXwq5WNL1ZrZD0ebzNyt6T6ss1lQlcX6N1yGpwzn3Qmz5h4qGIefWG10p6TXnXJdzbkTSjxU93zi3Tu9U59Kk/93PxPBbLakp1msqR9GbyA97XFPKiN2z+rqkzc65L4zb9LCk98fev1/S/0x3banGOfdXzrla51y9oufRL51z75X0pKQbY7vxXcU45/ZJ2m1mC2OrrpC0SZxbJ7NL0oVmVhD7Ozn2XXFund6pzqWHJb0v1uvzQkk945pHTyojR3gxs99W9F5NUNI3nHN/521FqcPMLpH0jKQNev0+1v9T9L7fQ5LmKDql1LudcxNvNvuWmV0u6c+cc9eZ2XxFrwTLJb0s6Xedc0MelpcyzGy5op2DciS1S/qAov/J5tyawMz+RtJ7FO2B/bKkDyp6n4pzS5KZfV/S5YpOXbRf0mcl/bdOci7F/gPxFUWbjvslfcA513ra42di+AEAcDqZ2OwJAMBpEX4AAN8h/AAAvkP4AQB8h/ADAPgO4QdkEDO7fGz2CQCnRvgBAHyH8AM8YGa/a2YvmtlaM7snNmdgr5l9MTbH2xNmFortu9zMno/NU/Zf4+YwazSzx81snZmtMbOG2OGLxs2p973YA8AAxiH8gGlmZosVHdnjYufccklhSe9VdHDjVufcOZKeUnREC0n6tqS/dM4tVXRknrH135N0t3NumaSLFJ0dQIrO1PExReeznK/omJEAxsk68y4AEuwKSRdIWh27KMtXdIDeiKQHY/t8V9KPY3PklTnnnoqtv0/SD8ysWFKNc+6/JMk5NyhJseO96JzriC2vlVQv6dmk/1ZAGiH8gOlnku5zzv3VCSvNPj1hv7Mde3D8WJBh8fcceAOaPYHp94SkG82sSpLMrNzM5ir693FsRP/fkfSsc65H0hEzuzS2/lZJTznnjknqMLO3x46Ra2YF0/lLAOmM/xEC08w5t8nMPiXpF2YWkDQi6Y8Unfx1ZWzbAUXvC0rRqVv+IxZuYzMlSNEgvMfM7owd46Zp/DWAtMasDkCKMLNe51yR13UAfkCzJwDAd7jyAwD4Dld+AADfIfwAAL5D+AEAfIfwAwD4DuEHAPCd/w/qBy3PUpwGFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\tloss             \t (min:    0.087, max:    0.164, cur:    0.087)\n",
      "[[-0.24536945 -0.29713486]\n",
      " [-0.19112033 -0.14383933]\n",
      " [-0.17157392 -0.17051829]\n",
      " ...\n",
      " [-0.53759743 -0.64941883]\n",
      " [-0.1654894  -0.19836119]\n",
      " [-0.41546174 -0.50183342]]\n",
      "\n",
      "[[-0.44091457 -0.59819428]\n",
      " [-0.38667611 -0.55940377]\n",
      " [-0.39522273 -0.4902451 ]\n",
      " [-0.46313379 -0.48509934]\n",
      " [-0.27914263 -0.33570518]\n",
      " [-0.51082384 -0.59466906]\n",
      " [-0.10166642 -0.12229333]\n",
      " [-0.49023811 -0.51032946]\n",
      " [-0.47169817 -0.64846569]\n",
      " [-0.37970998 -0.37390536]\n",
      " [-0.02331914 -0.03421659]\n",
      " [-0.35866946 -0.44030478]\n",
      " [-0.08660444 -0.12492164]\n",
      " [-0.19013463 -0.25813042]\n",
      " [-0.23439772 -0.34232201]\n",
      " [-0.43614456 -0.54303502]\n",
      " [-0.38893841 -0.51069856]\n",
      " [-0.36404875 -0.33099226]\n",
      " [-0.37606623 -0.60102459]\n",
      " [-0.05378833 -0.05581713]\n",
      " [-0.02514253 -0.02683027]\n",
      " [-0.04375478 -0.05808935]\n",
      " [-0.06902279 -0.08067348]\n",
      " [-0.05788994 -0.0827889 ]\n",
      " [-0.05816602 -0.07184519]\n",
      " [-0.3331905  -0.37740475]\n",
      " [-0.20694099 -0.25667259]\n",
      " [-0.06152075 -0.05558644]\n",
      " [-0.10775121 -0.12218284]\n",
      " [-0.28727444 -0.29589139]\n",
      " [-0.11719622 -0.11938853]\n",
      " [-0.06226376 -0.07692201]\n",
      " [-0.01621401 -0.02354769]\n",
      " [-0.19695701 -0.22953046]\n",
      " [-0.08003284 -0.08072964]\n",
      " [-0.10653886 -0.14676374]\n",
      " [-0.01669264 -0.02095889]\n",
      " [-0.15165904 -0.17541204]\n",
      " [-0.01335279 -0.01513161]\n",
      " [-0.0514793  -0.05010545]\n",
      " [-0.1018116  -0.11544442]\n",
      " [-0.07930372 -0.17142823]\n",
      " [-0.06950315 -0.08595255]\n",
      " [-0.11738789 -0.16582587]\n",
      " [-0.00356975 -0.00528021]\n",
      " [-0.00408641 -0.00618274]\n",
      " [-0.01631834 -0.01679665]\n",
      " [-0.10270836 -0.08375871]\n",
      " [-0.01532219 -0.01514498]\n",
      " [-0.01360555 -0.01324488]\n",
      " [-0.02396836 -0.05454092]\n",
      " [-0.00960193 -0.01245531]\n",
      " [-0.05143244 -0.05707054]\n",
      " [-0.00687203 -0.00735935]\n",
      " [-0.03246407 -0.03722634]\n",
      " [-0.07794633 -0.09688946]\n",
      " [-0.01317648 -0.02010323]\n",
      " [-0.01822416 -0.02130367]\n",
      " [-0.01909347 -0.02086714]\n",
      " [-0.02760395 -0.0393725 ]\n",
      " [-0.00771523 -0.0110351 ]\n",
      " [-0.03872369 -0.04589229]\n",
      " [-0.02885797 -0.04336896]\n",
      " [-0.01579654 -0.0129027 ]\n",
      " [-0.03832937 -0.04063137]\n",
      " [-0.00851368 -0.0098528 ]\n",
      " [-0.04713628 -0.0618511 ]\n",
      " [-0.0305964  -0.03347467]\n",
      " [-0.04264149 -0.03830827]\n",
      " [-0.01878288 -0.02049324]\n",
      " [-0.01489891 -0.01465603]\n",
      " [-0.01790011 -0.01793237]\n",
      " [-0.01844663 -0.01865931]\n",
      " [-0.00918938 -0.01015391]\n",
      " [-0.01170897 -0.0130695 ]\n",
      " [-0.01974263 -0.02430592]\n",
      " [-0.0602232  -0.06459911]\n",
      " [ 0.0036273  -0.0105029 ]\n",
      " [-0.00468719 -0.00570134]\n",
      " [-0.00353227 -0.00582151]\n",
      " [-0.02920213 -0.03161953]\n",
      " [-0.02474149 -0.03046326]\n",
      " [-0.0144264  -0.01581204]\n",
      " [-0.01597477 -0.02126347]\n",
      " [-0.01354731 -0.01783166]\n",
      " [-0.0110706  -0.01381865]\n",
      " [-0.00991379 -0.01651113]\n",
      " [-0.00905058 -0.01159284]\n",
      " [-0.00951448 -0.01184184]\n",
      " [-0.01572445 -0.02012176]\n",
      " [-0.01016781 -0.01342579]\n",
      " [-0.00115943 -0.00553768]\n",
      " [-0.0104733  -0.00634585]\n",
      " [-0.00434561 -0.0100795 ]\n",
      " [-0.00991712 -0.00720902]\n",
      " [-0.0042039  -0.00384394]\n",
      " [-0.01142358 -0.00668981]\n",
      " [-0.01696697 -0.01761126]\n",
      " [-0.00973156 -0.00834091]\n",
      " [-0.00521637 -0.00772037]]\n",
      "\n",
      "0.0873673314223\n"
     ]
    }
   ],
   "source": [
    "import livelossplot\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "def perform_mf_sgd_training(interactions_df, user_repr_matrix, item_repr_matrix, n_epochs, lr, reg_l):\n",
    "    liveloss = PlotLosses()\n",
    "    \n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "    \n",
    "        # Save and print epoch losses (this should be at the end of the loop over epochs)\n",
    "        \n",
    "        user_repr_matrix, item_repr_matrix, total_loss = perform_mf_sgd_epoch(interactions_df, user_repr_matrix, item_repr_matrix, lr, reg_l)\n",
    "\n",
    "        training_last_avg_loss = total_loss / len(interactions_df)\n",
    "\n",
    "        if epoch >= 3: # A bound on epoch prevents showing extremely high losses in the first epochs\n",
    "            logs = {'loss': training_last_avg_loss}\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()\n",
    "        \n",
    "        losses.append(total_loss)\n",
    "        \n",
    "    \n",
    "    return(user_repr_matrix,item_repr_matrix,training_last_avg_loss)\n",
    "        \n",
    "\n",
    "            \n",
    "# Test\n",
    "\n",
    "n_epochs = 100\n",
    "user_repr_matrix, item_repr_matrix, training_last_avg_loss \\\n",
    "    = perform_mf_sgd_training(interactions_pos_neg_df, user_repr_matrix, item_repr_matrix, n_epochs, lr, reg_l)\n",
    "\n",
    "print(user_repr_matrix)\n",
    "print()\n",
    "print(item_repr_matrix)\n",
    "print()\n",
    "print(training_last_avg_loss)\n",
    "\n",
    "# assert np.abs(total_loss - 5076.2638779478975) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-tennis",
   "metadata": {},
   "source": [
    "### Plot movie representations\n",
    "\n",
    "Remember that they don't have to be good as only two dimensions have been used. But still try to find if you can assign any meaning to those dimensions based on your knowledge about plotted movies. You can open the image in new tab and enlarge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True)\n",
    "fig.set_size_inches(64, 36)\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "sns.scatterplot(x=item_repr_matrix[:, 0], y=item_repr_matrix[:, 1], ax=ax1)\n",
    "\n",
    "for i in range(len(item_repr_matrix)):\n",
    "    title = ml_movies_df.loc[ml_movies_df['item_id'] == item_id_reverse_mapping[i], 'title'].iloc[0]\n",
    "    plt.text(x=item_repr_matrix[i, 0] + 1 / 150, y=item_repr_matrix[i, 1] + 1 / 150, s=title, \n",
    "             fontdict=dict(color='red', size=8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-powell",
   "metadata": {},
   "source": [
    "**Task 6.** Write the recommend method which takes user_id, interactions_df, user_repr_matrix, item_repr_matrix as input and returns the best recommendation (item_id) and its score for the given user based on scores calculated as dot products of the user representation (from user_repr_matrix) and item representations (item_repr_matrix). Remember to map the user id with user_id_mapping. Do not include films the user has already watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "piano-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best item id: 318\n",
      "Best item title: Shawshank Redemption, The (1994)\n",
      "Best item score: 0.30842207920504655\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def recommend(user_id, interactions_df, user_repr_matrix, item_repr_matrix):\n",
    "    ########################\n",
    "    # Write your code here #\n",
    "    ########################\n",
    "    uid = user_id_mapping[user_id]\n",
    "    watched = interactions_df.loc[interactions_df['user_id'] == uid, 'item_id'].unique()\n",
    "    watched_orig = [item_id_reverse_mapping[item_id] for item_id in watched]\n",
    "    item_id = -math.inf\n",
    "    score = -math.inf\n",
    "    for item in range(len(item_repr_matrix)):\n",
    "        if item in watched:\n",
    "            continue\n",
    "        item_score = np.dot(user_repr_matrix[uid], item_repr_matrix[item])\n",
    "        if item_score > score:\n",
    "            item_id = item\n",
    "            score = item_score\n",
    "    \n",
    "    return item_id, score\n",
    "\n",
    "\n",
    "# Test\n",
    "\n",
    "\n",
    "\n",
    "user_id = 1\n",
    "item_id, score = recommend(user_id, interactions_df, user_repr_matrix, item_repr_matrix)\n",
    "item_id = item_id_reverse_mapping[item_id]\n",
    "title = ml_movies_df.loc[ml_movies_df['item_id'] == item_id, 'title'].iloc[0]\n",
    "\n",
    "print(\"Best item id: {}\".format(item_id))\n",
    "print(\"Best item title: {}\".format(title))\n",
    "print(\"Best item score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-prediction",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Netflix Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "from recommenders.recommender import Recommender\n",
    "\n",
    "\n",
    "class NetflixRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Collaborative filtering based on matrix factorization with the following choice of an optimizer:\n",
    "      - Stochastic Gradient Descent (SGD),\n",
    "      - Mini-Batch Gradient Descent (MBGD),\n",
    "      - Alternating Least Squares (ALS).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, print_type=None, **params):\n",
    "        super().__init__()\n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.interactions_df = None\n",
    "        self.item_id_mapping = None\n",
    "        self.user_id_mapping = None\n",
    "        self.item_id_reverse_mapping = None\n",
    "        self.user_id_reverse_mapping = None\n",
    "        self.r = None\n",
    "        self.most_popular_items = None\n",
    "        \n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        if 'optimizer' in params:\n",
    "            self.optimizer = params['optimizer']\n",
    "        else:\n",
    "            self.optimizer = 'SGD'\n",
    "        if 'n_epochs' in params:  # number of epochs (each epoch goes through the entire training set)\n",
    "            self.n_epochs = params['n_epochs']\n",
    "        else:\n",
    "            self.n_epochs = 10\n",
    "        if 'lr' in params:  # learning rate\n",
    "            self.lr = params['lr']\n",
    "        else:\n",
    "            self.lr = 0.01\n",
    "        if 'reg_l' in params:  # regularization coefficient\n",
    "            self.reg_l = params['reg_l']\n",
    "        else:\n",
    "            self.reg_l = 0.1\n",
    "        if 'embedding_dim' in params:\n",
    "            self.embedding_dim = params['embedding_dim']\n",
    "        else:\n",
    "            self.embedding_dim = 8\n",
    "        \n",
    "        self.user_repr = None\n",
    "        self.item_repr = None\n",
    "\n",
    "        if 'should_recommend_already_bought' in params:\n",
    "            self.should_recommend_already_bought = params['should_recommend_already_bought']\n",
    "        else:\n",
    "            self.should_recommend_already_bought = False\n",
    "            \n",
    "        self.validation_set_size = 0.2\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)  \n",
    "        \n",
    "        self.print_type = print_type\n",
    "\n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "\n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items\n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by\n",
    "            user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined\n",
    "            by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "\n",
    "        del users_df, items_df\n",
    "\n",
    "        # Shift item ids and user ids so that they are consecutive\n",
    "\n",
    "        unique_item_ids = interactions_df['item_id'].unique()\n",
    "        self.item_id_mapping = dict(zip(unique_item_ids, list(range(len(unique_item_ids)))))\n",
    "        self.item_id_reverse_mapping = dict(zip(list(range(len(unique_item_ids))), unique_item_ids))\n",
    "        unique_user_ids = interactions_df['user_id'].unique()\n",
    "        self.user_id_mapping = dict(zip(unique_user_ids, list(range(len(unique_user_ids)))))\n",
    "        self.user_id_reverse_mapping = dict(zip(list(range(len(unique_user_ids))), unique_user_ids))\n",
    "\n",
    "        interactions_df = interactions_df.copy()\n",
    "        interactions_df['item_id'] = interactions_df['item_id'].map(self.item_id_mapping)\n",
    "        interactions_df['user_id'] = interactions_df['user_id'].map(self.user_id_mapping)\n",
    "\n",
    "        # Get the number of items and users\n",
    "\n",
    "        self.interactions_df = interactions_df\n",
    "        n_users = np.max(interactions_df['user_id']) + 1\n",
    "        n_items = np.max(interactions_df['item_id']) + 1\n",
    "\n",
    "        # Get the user-item interaction matrix (mapping to int is necessary because of how iterrows works)\n",
    "        r = np.zeros(shape=(n_users, n_items))\n",
    "        for idx, interaction in interactions_df.iterrows():\n",
    "            r[int(interaction['user_id'])][int(interaction['item_id'])] = 1\n",
    "\n",
    "        self.r = r\n",
    "        \n",
    "        # Indicate positive interactions\n",
    "        \n",
    "        interactions_df['interacted'] = 1\n",
    "\n",
    "        # Generate negative interactions\n",
    "        negative_interactions = []\n",
    "\n",
    "        i = 0\n",
    "        while i < self.n_neg_per_pos * len(interactions_df):\n",
    "            sample_size = 1000\n",
    "            user_ids = self.rng.choice(np.arange(n_users), size=sample_size)\n",
    "            item_ids = self.rng.choice(np.arange(n_items), size=sample_size)\n",
    "\n",
    "            j = 0\n",
    "            while j < sample_size and i < self.n_neg_per_pos * len(interactions_df):\n",
    "                if r[user_ids[j]][item_ids[j]] == 0:\n",
    "                    negative_interactions.append([user_ids[j], item_ids[j], 0])\n",
    "                    i += 1\n",
    "                j += 1\n",
    "        \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        \n",
    "        # Initialize user and item embeddings as random vectors (from Gaussian distribution)\n",
    "        \n",
    "        self.user_repr = self.rng.normal(0, 1, size=(r.shape[0], self.embedding_dim))\n",
    "        self.item_repr = self.rng.normal(0, 1, size=(r.shape[1], self.embedding_dim))\n",
    "        \n",
    "        # Initialize losses and loss visualization\n",
    "        \n",
    "        if self.print_type is not None and self.print_type == 'live':\n",
    "            liveloss = PlotLosses()\n",
    "\n",
    "        training_losses = deque(maxlen=50)\n",
    "        training_avg_losses = []\n",
    "        training_epoch_losses = []\n",
    "        validation_losses = deque(maxlen=50)\n",
    "        validation_avg_losses = []\n",
    "        validation_epoch_losses = []\n",
    "        last_training_total_loss = 0.0\n",
    "        last_validation_total_loss = 0.0\n",
    "        \n",
    "        # Split the data\n",
    "        \n",
    "        interaction_ids = self.rng.permutation(len(interactions_df))\n",
    "        train_validation_slice_idx = int(len(interactions_df) * (1 - self.validation_set_size))\n",
    "        training_ids = interaction_ids[:train_validation_slice_idx]\n",
    "        validation_ids = interaction_ids[train_validation_slice_idx:]\n",
    "        \n",
    "        # Train the model\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            if self.print_type is not None and self.print_type == 'live':\n",
    "                logs = {}\n",
    "            \n",
    "            # Train\n",
    "            \n",
    "            training_losses.clear()\n",
    "            training_total_loss = 0.0\n",
    "            batch_idx = 0\n",
    "            for idx in training_ids:\n",
    "                user_id = int(interactions_df.iloc[idx]['user_id'])\n",
    "                item_id = int(interactions_df.iloc[idx]['item_id'])\n",
    "                r_ui = interactions_df.iloc[idx]['interacted']\n",
    "            \n",
    "                e_ui = r_ui - np.dot(self.user_repr[user_id], self.item_repr[item_id])\n",
    "                self.user_repr[user_id] = self.user_repr[user_id] \\\n",
    "                    + self.lr * (e_ui * self.item_repr[item_id] - self.reg_l * self.user_repr[user_id])\n",
    "                self.item_repr[item_id] = self.item_repr[item_id] \\\n",
    "                    + self.lr * (e_ui * self.user_repr[user_id] - self.reg_l * self.item_repr[item_id])\n",
    "                \n",
    "                loss = e_ui**2\n",
    "                training_total_loss += loss\n",
    "                \n",
    "                if self.print_type is not None and self.print_type == 'text':\n",
    "                    print('\\rEpoch: {}\\tBatch: {}\\tLast epoch - avg training loss: {:.2f} avg validation loss: {:.2f} loss: {}'.format(\n",
    "                        epoch, batch_idx, last_training_total_loss, last_validation_total_loss, loss), end=\"\")\n",
    "                    \n",
    "                batch_idx += 1\n",
    "                \n",
    "                training_losses.append(loss)\n",
    "                training_avg_losses.append(np.mean(training_losses))\n",
    "                \n",
    "            # Validate\n",
    "            \n",
    "            validation_losses.clear()\n",
    "            validation_total_loss = 0.0\n",
    "            for idx in validation_ids:\n",
    "                user_id = int(interactions_df.iloc[idx]['user_id'])\n",
    "                item_id = int(interactions_df.iloc[idx]['item_id'])\n",
    "            \n",
    "                e_ui = r[user_id, item_id] - np.dot(self.user_repr[user_id], self.item_repr[item_id])\n",
    "                \n",
    "                loss = e_ui**2\n",
    "                validation_total_loss += loss\n",
    "\n",
    "                validation_losses.append(loss)\n",
    "                validation_avg_losses.append(np.mean(validation_losses))\n",
    "                \n",
    "            # Save and print epoch losses\n",
    "            \n",
    "            training_last_avg_loss = training_total_loss / len(training_ids)\n",
    "            validation_last_avg_loss = validation_total_loss / len(validation_ids)\n",
    "\n",
    "            if self.print_type is not None and self.print_type == 'live' and epoch >= 3:\n",
    "                # A bound on epoch prevents showing extremely high losses in the first epochs\n",
    "                logs['loss'] = training_last_avg_loss\n",
    "                logs['val_loss'] = validation_last_avg_loss\n",
    "                liveloss.update(logs)\n",
    "                liveloss.send()\n",
    "\n",
    "        # Find the most popular items for the cold start problem\n",
    "\n",
    "        offers_count = interactions_df.loc[:, ['item_id', 'user_id']].groupby(by='item_id').count()\n",
    "        offers_count = offers_count.sort_values('user_id', ascending=False)\n",
    "        self.most_popular_items = offers_count.index\n",
    "\n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns\n",
    "        top n_recommendations for each user.\n",
    "\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which\n",
    "            recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations\n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "\n",
    "        # Handle users not in the training data\n",
    "\n",
    "        # Map item ids\n",
    "\n",
    "        items_df = items_df.copy()\n",
    "        items_df = items_df.loc[items_df['item_id'].isin(self.item_id_mapping)]\n",
    "        items_df.replace({'item_id': self.item_id_mapping}, inplace=True)\n",
    "\n",
    "        # Generate recommendations\n",
    "\n",
    "        for idx, user in users_df.iterrows():\n",
    "            recommendations = []\n",
    "\n",
    "            user_id = user['user_id']\n",
    "\n",
    "            if user_id in self.user_id_mapping:\n",
    "                mapped_user_id = self.user_id_mapping[user_id]\n",
    "                \n",
    "                ids_list = items_df['item_id'].tolist()\n",
    "                id_to_pos = np.array([0]*len(ids_list))\n",
    "                for k in range(len(ids_list)):\n",
    "                    id_to_pos[ids_list[k]] = k\n",
    "                scores = np.matmul(self.user_repr[mapped_user_id].reshape(1, -1), \n",
    "                                   self.item_repr[ids_list].T).flatten()\n",
    "                \n",
    "                # Choose n recommendations based on highest scores\n",
    "                if not self.should_recommend_already_bought:\n",
    "                    x_list = self.interactions_df.loc[\n",
    "                        self.interactions_df['user_id'] == mapped_user_id]['item_id'].tolist()\n",
    "                    scores[id_to_pos[x_list]] = -1e100\n",
    "\n",
    "                chosen_pos = np.argsort(-scores)[:n_recommendations]\n",
    "\n",
    "                for item_pos in chosen_pos:\n",
    "                    recommendations.append(\n",
    "                        {\n",
    "                            'user_id': self.user_id_reverse_mapping[mapped_user_id],\n",
    "                            'item_id': self.item_id_reverse_mapping[ids_list[item_pos]],\n",
    "                            'score': scores[item_pos]\n",
    "                        }\n",
    "                    )\n",
    "            else:  # For new users recommend most popular items\n",
    "                for i in range(n_recommendations):\n",
    "                    recommendations.append(\n",
    "                        {\n",
    "                            'user_id': user['user_id'],\n",
    "                            'item_id': self.item_id_reverse_mapping[self.most_popular_items[i]],\n",
    "                            'score': 1.0\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df\n",
    "    \n",
    "    def get_user_repr(self, user_id):\n",
    "        mapped_user_id = self.user_id_mapping[user_id]\n",
    "        return self.user_repr[mapped_user_id]\n",
    "    \n",
    "    def get_item_repr(self, item_id):\n",
    "        mapped_item_id = self.item_id_mapping[item_id]\n",
    "        return self.item_repr[mapped_item_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-offering",
   "metadata": {},
   "source": [
    "## Quick test of the recommender (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_recommender = NetflixRecommender(print_type='live', embedding_dim=8, n_epochs=200)\n",
    "netflix_recommender.fit(ml_ratings_df, None, ml_movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-messaging",
   "metadata": {},
   "source": [
    "## Quick test of the recommender (recommending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = netflix_recommender.recommend(pd.DataFrame([[1], [4], [6]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id', how='left')\n",
    "print(\"Recommendations\")\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-barcelona",
   "metadata": {},
   "source": [
    "## User and item representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1\n",
    "user_repr = netflix_recommender.get_user_repr(user_id=user_id)\n",
    "print(\"User id={}\".format(user_id))\n",
    "print(user_repr)\n",
    "print()\n",
    "\n",
    "print(\"User watched\")\n",
    "print(ml_df.loc[ml_df['user_id'] == user_id, 'title'].tolist())\n",
    "print()\n",
    "\n",
    "print('User history item representations')\n",
    "for item_id in ml_df.loc[ml_df['user_id'] == user_id, 'item_id'].tolist():\n",
    "    item_repr = netflix_recommender.get_item_repr(item_id=item_id)\n",
    "    print(\"Item id = {}\\titem title = {}\".format(item_id, ml_movies_df.loc[ml_movies_df['item_id'] == item_id, 'title'].iloc[0]))\n",
    "    print(item_repr)\n",
    "    score = np.dot(user_repr, item_repr)\n",
    "    print(\"Score={:.6f}\".format(score))\n",
    "    print()\n",
    "\n",
    "print(\"===============\")\n",
    "    \n",
    "item_id = 145\n",
    "item_repr = netflix_recommender.get_item_repr(item_id=item_id)\n",
    "print(\"Item id = {}\\titem title = {}\".format(item_id, ml_movies_df.loc[ml_movies_df['item_id'] == item_id, 'title'].iloc[0]))\n",
    "print(item_repr)\n",
    "score = np.dot(user_repr, item_repr)\n",
    "print(\"Score={:.6f}\".format(score))\n",
    "print()\n",
    "\n",
    "item_id = 171\n",
    "item_repr = netflix_recommender.get_item_repr(item_id=item_id)\n",
    "print(\"Item id = {}\\titem title = {}\".format(item_id, ml_movies_df.loc[ml_movies_df['item_id'] == item_id, 'title'].iloc[0]))\n",
    "print(item_repr)\n",
    "score = np.dot(user_repr, item_repr)\n",
    "print(\"Score={:.6f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-negative",
   "metadata": {},
   "source": [
    "# Training-test split evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_recommender = NetflixRecommender(n_epochs=150)\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.tfidf_recommender import TFIDFRecommender\n",
    "\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "tfidf_tts_results = [['TFIDFRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "tfidf_tts_results = pd.DataFrame(\n",
    "    tfidf_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(tfidf_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_results = pd.concat([netflix_tts_results, amazon_tts_results, tfidf_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-harassment",
   "metadata": {},
   "source": [
    "# Leave-one-out evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_leave_one_out_implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_recommender = NetflixRecommender(n_epochs=10)\n",
    "\n",
    "netflix_loo_results = [['NetflixRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    netflix_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "netflix_loo_results = pd.DataFrame(\n",
    "    netflix_loo_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_loo_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_loo_results = [['AmazonRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    amazon_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "amazon_loo_results = pd.DataFrame(\n",
    "    amazon_loo_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_loo_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "tfidf_loo_results = [['TFIDFRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "tfidf_loo_results = pd.DataFrame(\n",
    "    tfidf_loo_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(tfidf_loo_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_results = pd.concat([netflix_loo_results, amazon_loo_results, tfidf_loo_results]).reset_index(drop=True)\n",
    "display(HTML(loo_results.to_html()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
